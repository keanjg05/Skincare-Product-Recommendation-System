{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "BASELINE RECOMMENDATION SYSTEM\n",
        "============================================================================\n",
        "Purpose: Establish baseline using pre-trained SBERT + rule-based matching\n",
        "This serves as a comparison point for the trained neural network\n",
        "\n",
        "This notebook implements a baseline using:\n",
        "\n",
        "  • Pre-trained Sentence-BERT for semantic similarity\n",
        "\n",
        "  • Rule-based skin type matching\n",
        "  \n",
        "  • Simple weighted combination"
      ],
      "metadata": {
        "id": "fFmf2CkQXsvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "DfRrbkONXs41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Data**"
      ],
      "metadata": {
        "id": "W04Oly27XtAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load products\n",
        "products_df = pd.read_csv('/content/drive/MyDrive/cosmetic_p.csv')\n",
        "print(f\"\\n Loaded {len(products_df)} products\")\n",
        "\n",
        "# Load pre-trained SBERT model\n",
        "print(\"\\n Loading pre-trained Sentence-BERT model...\")\n",
        "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\" Model loaded: all-MiniLM-L6-v2 (384-dim embeddings)\")\n",
        "\n",
        "# Check for existing embeddings or generate new ones\n",
        "import os\n",
        "if os.path.exists('product_embeddings.npy'):\n",
        "    print(\"\\n Loading existing product embeddings...\")\n",
        "    product_embeddings = np.load('product_embeddings.npy')\n",
        "else:\n",
        "    print(\"\\n Generating product embeddings (2-3 minutes)...\")\n",
        "    product_texts = products_df['ingredients'].fillna('').tolist()\n",
        "    product_embeddings = sbert_model.encode(\n",
        "        product_texts,\n",
        "        show_progress_bar=True,\n",
        "        batch_size=32,\n",
        "        normalize_embeddings=True\n",
        "    )\n",
        "    np.save('product_embeddings.npy', product_embeddings)\n",
        "    print(\" Saved embeddings\")\n",
        "\n",
        "print(f\" Product embeddings ready: {product_embeddings.shape}\")"
      ],
      "metadata": {
        "id": "2_UUN9DaXtF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Baseline System Components**"
      ],
      "metadata": {
        "id": "TYxO_BK7XtMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_query_skin_types(query):\n",
        "    \"\"\"\n",
        "    Rule-based extraction of skin types from query text.\n",
        "    Returns list of detected skin types.\n",
        "    \"\"\"\n",
        "    query_lower = query.lower()\n",
        "    detected = []\n",
        "\n",
        "    skin_type_keywords = {\n",
        "        'Dry': ['dry', 'dehydrated', 'flaky', 'tight'],\n",
        "        'Oily': ['oily', 'greasy', 'shiny', 'sebum'],\n",
        "        'Combination': ['combination', 'combo', 't-zone'],\n",
        "        'Normal': ['normal', 'balanced'],\n",
        "        'Sensitive': ['sensitive', 'reactive', 'redness', 'irritated']\n",
        "    }\n",
        "\n",
        "    for skin_type, keywords in skin_type_keywords.items():\n",
        "        if any(kw in query_lower for kw in keywords):\n",
        "            detected.append(skin_type)\n",
        "\n",
        "    return detected if detected else []\n",
        "\n",
        "\n",
        "def calculate_skin_type_match(product_row, query_skin_types):\n",
        "    \"\"\"\n",
        "    Calculate how well product matches query skin types using explicit rules.\n",
        "    Returns score 0-1.\n",
        "\n",
        "    This is a RULE-BASED component (not learned).\n",
        "    \"\"\"\n",
        "    if not query_skin_types:\n",
        "        return 0.5\n",
        "\n",
        "    product_skin_types = [\n",
        "        st for st in ['Dry', 'Oily', 'Combination', 'Normal', 'Sensitive']\n",
        "        if product_row[st] == 1\n",
        "    ]\n",
        "\n",
        "    if not product_skin_types:\n",
        "        return 0.0\n",
        "\n",
        "    # Count matches\n",
        "    matches = sum([1 for st in query_skin_types if st in product_skin_types])\n",
        "\n",
        "    if matches == 0:\n",
        "        return 0.0\n",
        "\n",
        "    # Score based on match quality\n",
        "    match_ratio = matches / len(query_skin_types)\n",
        "\n",
        "    # Penalty for generic products (too many skin types)\n",
        "    num_product_types = len(product_skin_types)\n",
        "    genericity_penalty = (num_product_types - 1) / 4.0\n",
        "\n",
        "    # Final score: match quality minus genericity penalty\n",
        "    score = match_ratio * (1.0 - genericity_penalty * 0.3)\n",
        "\n",
        "    return max(0.0, min(1.0, score))\n",
        "\n",
        "\n",
        "def get_baseline_scores(query, products_df, product_embeddings, sbert_model,\n",
        "                       skin_type_weight=0.7, semantic_weight=0.3):\n",
        "    \"\"\"\n",
        "    Calculate compatibility using baseline approach.\n",
        "\n",
        "    Components (NO TRAINING):\n",
        "    1. Skin type matching (70% weight) - hand-coded rules\n",
        "    2. Semantic similarity (30% weight) - pre-trained SBERT\n",
        "    \"\"\"\n",
        "    # Get query embedding using PRE-TRAINED model\n",
        "    query_embedding = sbert_model.encode([query], normalize_embeddings=True)[0]\n",
        "\n",
        "    # Extract query skin types using RULES\n",
        "    query_skin_types = extract_query_skin_types(query)\n",
        "\n",
        "    # Calculate scores for all products\n",
        "    scores = []\n",
        "\n",
        "    for i in range(len(products_df)):\n",
        "        product_row = products_df.iloc[i]\n",
        "        product_emb = product_embeddings[i]\n",
        "\n",
        "        # Component 1: Rule-based skin type matching\n",
        "        skin_type_score = calculate_skin_type_match(product_row, query_skin_types)\n",
        "\n",
        "        # Component 2: Semantic similarity (cosine similarity of embeddings)\n",
        "        semantic_score = np.dot(query_embedding, product_emb)\n",
        "        semantic_score = (semantic_score + 1) / 2\n",
        "\n",
        "        # Simple weighted combination (no learning)\n",
        "        final_score = (\n",
        "            skin_type_score * skin_type_weight +\n",
        "            semantic_score * semantic_weight\n",
        "        )\n",
        "\n",
        "        scores.append({\n",
        "            'idx': i,\n",
        "            'final_score': final_score,\n",
        "            'skin_type_score': skin_type_score,\n",
        "            'semantic_score': semantic_score\n",
        "        })\n",
        "\n",
        "    return scores, query_skin_types\n",
        "\n",
        "\n",
        "def recommend_top_k_baseline(query, k=5):\n",
        "    \"\"\"Get top-K recommendations using baseline approach.\"\"\"\n",
        "    scores, query_skin_types = get_baseline_scores(\n",
        "        query, products_df, product_embeddings, sbert_model\n",
        "    )\n",
        "\n",
        "    # Sort by final score\n",
        "    scores.sort(key=lambda x: x['final_score'], reverse=True)\n",
        "\n",
        "    # Get top K with simple diversity constraint\n",
        "    selected = []\n",
        "    selected_brands = set()\n",
        "\n",
        "    for item in scores:\n",
        "        if len(selected) >= k:\n",
        "            break\n",
        "\n",
        "        idx = item['idx']\n",
        "        product = products_df.iloc[idx]\n",
        "        brand = product['brand']\n",
        "\n",
        "        # Diversity: limit 2 products per brand\n",
        "        brand_count = sum([1 for s in selected if products_df.iloc[s['idx']]['brand'] == brand])\n",
        "\n",
        "        if brand_count < 2:\n",
        "            selected.append(item)\n",
        "            selected_brands.add(brand)\n",
        "\n",
        "    # Build results\n",
        "    results = []\n",
        "    for rank, item in enumerate(selected, 1):\n",
        "        idx = item['idx']\n",
        "        product = products_df.iloc[idx]\n",
        "\n",
        "        product_skin_types = [\n",
        "            st for st in ['Dry', 'Oily', 'Combination', 'Normal', 'Sensitive']\n",
        "            if product[st] == 1\n",
        "        ]\n",
        "\n",
        "        # Check if product matches query\n",
        "        matches_query = any([st in product_skin_types for st in query_skin_types]) if query_skin_types else True\n",
        "\n",
        "        results.append({\n",
        "            'rank': rank,\n",
        "            'name': product['name'],\n",
        "            'brand': product['brand'],\n",
        "            'category': product['Label'],\n",
        "            'price': product['price'],\n",
        "            'rating': product['rank'],\n",
        "            'final_score': item['final_score'],\n",
        "            'skin_type_score': item['skin_type_score'],\n",
        "            'semantic_score': item['semantic_score'],\n",
        "            'skin_types': ', '.join(product_skin_types) if product_skin_types else 'Not specified',\n",
        "            'matches_query': matches_query,\n",
        "            'query_skin_types': ', '.join(query_skin_types) if query_skin_types else 'None detected'\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def display_baseline_results(results, query):\n",
        "    \"\"\"Display baseline recommendations with analysis.\"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\" QUERY: '{query}'\")\n",
        "    print(f\"Detected skin types: {results[0]['query_skin_types']}\")\n",
        "    print(f\"\\n TOP {len(results)} BASELINE RECOMMENDATIONS:\\n\")\n",
        "\n",
        "    matches = 0\n",
        "    for r in results:\n",
        "        match_indicator = \"✓\" if r['matches_query'] else \"X\"\n",
        "        if r['matches_query']:\n",
        "            matches += 1\n",
        "\n",
        "        print(f\"#{r['rank']}. {r['name']} {match_indicator}\")\n",
        "        print(f\"    Brand:        {r['brand']}\")\n",
        "        print(f\"    Category:     {r['category']}\")\n",
        "        print(f\"    Price:        ${r['price']:.2f}\")\n",
        "        print(f\"    Rating:       {r['rating']:.1f}/5.0\")\n",
        "        print(f\"    For:          {r['skin_types']}\")\n",
        "        print(f\"    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n",
        "        print(f\"    Skin Match:   {r['skin_type_score']:.1%} (rule-based)\")\n",
        "        print(f\"    Semantic:     {r['semantic_score']:.1%} (SBERT)\")\n",
        "        print(f\"    FINAL:        {r['final_score']:.1%} \")\n",
        "        print()\n",
        "\n",
        "    match_rate = matches / len(results) * 100\n",
        "    print(f\" MATCH RATE: {matches}/{len(results)} ({match_rate:.0f}%) match query skin types\")\n",
        "\n",
        "    return match_rate"
      ],
      "metadata": {
        "id": "PuWBYm1HXtRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate baseline on Test Queries"
      ],
      "metadata": {
        "id": "cVXBQhc9XtXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_queries = [\n",
        "    \"dry sensitive skin with redness\",\n",
        "    \"oily acne prone skin\",\n",
        "    \"combination skin with dark spots\",\n",
        "    \"mature skin with wrinkles\"\n",
        "]\n",
        "\n",
        "print(\"\\n Testing baseline on sample queries...\\n\")\n",
        "\n",
        "all_match_rates = []\n",
        "\n",
        "for query in test_queries:\n",
        "    results = recommend_top_k_baseline(query, k=5)\n",
        "    match_rate = display_baseline_results(results, query)\n",
        "    all_match_rates.append(match_rate)\n",
        "    print(\"\\n\" + \"-\"*80 + \"\\n\")"
      ],
      "metadata": {
        "id": "QHOvo19PXtc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Baseline Performance Summary**"
      ],
      "metadata": {
        "id": "RuNKmer1Xtie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_match_rate = np.mean(all_match_rates)\n",
        "\n",
        "print(f\"\\n Baseline Statistics:\")\n",
        "print(f\"   Average match rate: {avg_match_rate:.1f}%\")\n",
        "print(f\"   Best query: {max(all_match_rates):.0f}%\")\n",
        "print(f\"   Worst query: {min(all_match_rates):.0f}%\")\n",
        "print(f\"   Standard deviation: {np.std(all_match_rates):.1f}%\")\n",
        "\n",
        "print(f\"\\n Baseline Performance:\")\n",
        "if avg_match_rate >= 80:\n",
        "    print(f\"    STRONG: {avg_match_rate:.0f}% match rate\")\n",
        "    print(f\"   The baseline is working well - will be hard to beat!\")\n",
        "elif avg_match_rate >= 60:\n",
        "    print(f\"    GOOD: {avg_match_rate:.0f}% match rate\")\n",
        "    print(f\"   Solid baseline - neural network needs to beat this\")\n",
        "elif avg_match_rate >= 40:\n",
        "    print(f\"     MODERATE: {avg_match_rate:.0f}% match rate\")\n",
        "    print(f\"   Baseline is okay - room for improvement\")\n",
        "else:\n",
        "    print(f\"     WEAK: {avg_match_rate:.0f}% match rate\")\n",
        "    print(f\"   Low baseline - easier for neural network to beat\")\n",
        "\n"
      ],
      "metadata": {
        "id": "EG7v5msHXtoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation"
      ],
      "metadata": {
        "id": "LynBZ_3Gsbvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "Pd37IuczsiyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "File Upload"
      ],
      "metadata": {
        "id": "KNhGHhNMskyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directories\n",
        "os.makedirs('./data', exist_ok=True)\n",
        "os.makedirs('./models', exist_ok=True)\n",
        "\n",
        "print(' UPLOAD NEURAL NETWORK FILES')\n",
        "print('\\nPlease upload the following files:')\n",
        "print('1. skincarefull.pth (trained model)')\n",
        "print('2. product_embeddings.npy')\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Handle each file\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.zip'):\n",
        "        # Extract zip to models directory\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall('./models/')\n",
        "        print(f' Extracted {filename} to ./models/')\n",
        "\n",
        "        # Check what was extracted\n",
        "        extracted_files = os.listdir('./models/')\n",
        "        print(f'   Extracted files: {extracted_files}')\n",
        "    elif filename.endswith('.pth'):\n",
        "        # Move model file to models directory\n",
        "        target_path = f'./models/{filename}'\n",
        "        with open(target_path, 'wb') as f:\n",
        "            f.write(uploaded[filename])\n",
        "        print(f' Moved {filename} to ./models/')\n",
        "    elif filename.endswith('.npy'):\n",
        "        # Move embeddings to data directory\n",
        "        target_path = f'./data/{filename}'\n",
        "        with open(target_path, 'wb') as f:\n",
        "            f.write(uploaded[filename])\n",
        "        print(f' Moved {filename} to ./data/')\n",
        "\n",
        "print('\\n Upload complete!\\n')"
      ],
      "metadata": {
        "id": "QJIgWMcRsm8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Model"
      ],
      "metadata": {
        "id": "5HpfQNWksrYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CompatibilityNetV1(nn.Module):\n",
        "    \"\"\"Original architecture (512->256->128)\"\"\"\n",
        "    def __init__(self, input_dim=770):\n",
        "        super(CompatibilityNetV1, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "class CompatibilityNetV2(nn.Module):\n",
        "    \"\"\"Architecture with BatchNorm (256->128->64)\"\"\"\n",
        "    def __init__(self, input_dim=770):\n",
        "        super(CompatibilityNetV2, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "# Find the model file\n",
        "model_files = [f for f in os.listdir('./models/') if f.endswith('.pth')]\n",
        "if not model_files:\n",
        "    raise FileNotFoundError(\"No .pth model file found in ./models/\")\n",
        "\n",
        "model_path = f'./models/{model_files[0]}'\n",
        "print(f\" Loading model from: {model_path}\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\" Device: {device}\")\n",
        "\n",
        "# Load checkpoint and detect architecture\n",
        "print(\" Loading checkpoint and detecting architecture...\")\n",
        "\n",
        "try:\n",
        "    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
        "\n",
        "    if 'model_state_dict' in checkpoint:\n",
        "        state_dict = checkpoint['model_state_dict']\n",
        "    else:\n",
        "        state_dict = checkpoint\n",
        "\n",
        "    # Detect architecture by checking layer shapes\n",
        "    first_layer_shape = state_dict['network.0.weight'].shape\n",
        "    has_batchnorm = any('running_mean' in key for key in state_dict.keys())\n",
        "\n",
        "    print(f\"   First layer shape: {first_layer_shape}\")\n",
        "    print(f\"   Has BatchNorm: {has_batchnorm}\")\n",
        "\n",
        "    # Choose the right architecture\n",
        "    if first_layer_shape[0] == 256 and has_batchnorm:\n",
        "        print(\"   -> Detected architecture: V2 (256->128->64 with BatchNorm)\")\n",
        "        model = CompatibilityNetV2()\n",
        "    elif first_layer_shape[0] == 512:\n",
        "        print(\"   -> Detected architecture: V1 (512->256->128)\")\n",
        "        model = CompatibilityNetV1()\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown architecture with first layer shape {first_layer_shape}\")\n",
        "\n",
        "    # Load the weights\n",
        "    model.load_state_dict(state_dict)\n",
        "    print(\" Loaded model weights from checkpoint\")\n",
        "\n",
        "    # Show optional training info\n",
        "    if isinstance(checkpoint, dict) and 'hyperparameters' in checkpoint:\n",
        "        print(f\"   Hyperparameters: {checkpoint['hyperparameters']}\")\n",
        "    if isinstance(checkpoint, dict) and 'history' in checkpoint:\n",
        "        history = checkpoint['history']\n",
        "        if 'val_loss' in history and len(history['val_loss']) > 0:\n",
        "            best_val_loss = min(history['val_loss'])\n",
        "            print(f\"   Best validation loss: {best_val_loss:.4f}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\" Error loading model: {e}\")\n",
        "    print(\"\\n If this persists, please share:\")\n",
        "    print(\"   1. How you saved your model (torch.save code)\")\n",
        "    print(\"   2. The model architecture from your training notebook\")\n",
        "    raise\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "print(\" Model ready for evaluation\")\n",
        "\n",
        "# Check if we need to use uploaded embeddings or existing ones\n",
        "if os.path.exists('./data/product_embeddings.npy'):\n",
        "    print(\"\\n  Found uploaded product_embeddings.npy\")\n",
        "    use_new = input(\"Use this instead of the existing embeddings? (yes/no): \").lower()\n",
        "    if use_new == 'yes':\n",
        "        product_embeddings = np.load('./data/product_embeddings.npy')\n",
        "        print(\" Using uploaded embeddings\")\n",
        "    else:\n",
        "        print(\" Using existing embeddings from earlier\")\n",
        "else:\n",
        "    print(\" Using existing product embeddings from earlier\")\n",
        "\n",
        "# Prepare price_rank_features (needed for model input)\n",
        "print(\"\\n Preparing features for neural network...\")\n",
        "price_rank_features = np.column_stack([\n",
        "    products_df['price'].values,\n",
        "    products_df['rank'].values\n",
        "])\n",
        "print(f\" Features ready: {price_rank_features.shape}\")\n",
        "\n",
        "# Define enhanced functions (specificity-aware)\n",
        "def calculate_specificity_score(product_row):\n",
        "    \"\"\"Calculate how specific a product is (fewer skin types = more specific).\"\"\"\n",
        "    skin_type_cols = ['Dry', 'Oily', 'Combination', 'Normal', 'Sensitive']\n",
        "    num_skin_types = sum([product_row[col] for col in skin_type_cols])\n",
        "    specificity = 1.0 - (num_skin_types - 1) / 4.0 if num_skin_types > 0 else 0.0\n",
        "    return specificity\n",
        "\n",
        "def extract_query_skin_types_nn(query):\n",
        "    \"\"\"Extract mentioned skin types from query text.\"\"\"\n",
        "    query_lower = query.lower()\n",
        "    detected = []\n",
        "\n",
        "    skin_type_keywords = {\n",
        "        'Dry': ['dry', 'dehydrated', 'flaky', 'tight'],\n",
        "        'Oily': ['oily', 'greasy', 'shiny', 'sebum'],\n",
        "        'Combination': ['combination', 'combo', 't-zone'],\n",
        "        'Normal': ['normal', 'balanced'],\n",
        "        'Sensitive': ['sensitive', 'reactive', 'redness', 'irritated']\n",
        "    }\n",
        "\n",
        "    for skin_type, keywords in skin_type_keywords.items():\n",
        "        if any(kw in query_lower for kw in keywords):\n",
        "            detected.append(skin_type)\n",
        "\n",
        "    return detected if detected else []\n",
        "\n",
        "def calculate_match_precision(product_row, query_skin_types):\n",
        "    \"\"\"Calculate how precisely a product matches the query's skin types.\"\"\"\n",
        "    if not query_skin_types:\n",
        "        return 0.5\n",
        "\n",
        "    product_skin_types = [\n",
        "        st for st in ['Dry', 'Oily', 'Combination', 'Normal', 'Sensitive']\n",
        "        if product_row[st] == 1\n",
        "    ]\n",
        "\n",
        "    matches = sum([1 for st in query_skin_types if st in product_skin_types])\n",
        "    precision = matches / len(query_skin_types) if query_skin_types else 0.5\n",
        "\n",
        "    # Bonus for exact match\n",
        "    if set(query_skin_types) == set(product_skin_types):\n",
        "        precision += 0.2\n",
        "\n",
        "    return min(precision, 1.0)\n",
        "\n",
        "def get_nn_base_scores(query):\n",
        "    \"\"\"Get base neural network predictions (no enhancements).\"\"\"\n",
        "    query_emb = sbert_model.encode([query], normalize_embeddings=True)[0]\n",
        "\n",
        "    batch_features = []\n",
        "    for i in range(len(products_df)):\n",
        "        product_emb = product_embeddings[i]\n",
        "        numerical = price_rank_features[i]\n",
        "        features = np.concatenate([query_emb, product_emb, numerical])\n",
        "        batch_features.append(features)\n",
        "\n",
        "    batch_tensor = torch.FloatTensor(np.array(batch_features)).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        scores = model(batch_tensor).cpu().numpy().flatten()\n",
        "\n",
        "    return scores\n",
        "\n",
        "def get_nn_enhanced_scores(query, specificity_weight=0.3, precision_weight=0.2):\n",
        "    \"\"\"Get enhanced neural network scores with specificity and precision.\"\"\"\n",
        "    base_scores = get_nn_base_scores(query)\n",
        "    query_skin_types = extract_query_skin_types_nn(query)\n",
        "\n",
        "    enhanced_scores = base_scores.copy()\n",
        "\n",
        "    for i in range(len(products_df)):\n",
        "        product_row = products_df.iloc[i]\n",
        "\n",
        "        # Calculate enhancements\n",
        "        specificity = calculate_specificity_score(product_row)\n",
        "        precision = calculate_match_precision(product_row, query_skin_types)\n",
        "\n",
        "        # Apply multiplicative boosts\n",
        "        enhanced_scores[i] = (\n",
        "            base_scores[i] *\n",
        "            (1.0 + specificity * specificity_weight) *\n",
        "            (1.0 + precision * precision_weight)\n",
        "        )\n",
        "\n",
        "    # Normalize\n",
        "    if enhanced_scores.max() > 0:\n",
        "        enhanced_scores = enhanced_scores / enhanced_scores.max()\n",
        "\n",
        "    return enhanced_scores, base_scores, query_skin_types\n",
        "\n",
        "def recommend_nn_enhanced(query, k=5, filter_no_skin_type=True):\n",
        "    \"\"\"Get enhanced neural network recommendations with optional filtering.\"\"\"\n",
        "    enhanced_scores, base_scores, query_skin_types = get_nn_enhanced_scores(query)\n",
        "\n",
        "    # Optional: Filter out products with no skin type data\n",
        "    valid_indices = []\n",
        "    for i in range(len(products_df)):\n",
        "        if filter_no_skin_type:\n",
        "            skin_type_count = sum([\n",
        "                products_df.iloc[i][st] for st in ['Dry', 'Oily', 'Combination', 'Normal', 'Sensitive']\n",
        "            ])\n",
        "            if skin_type_count > 0:\n",
        "                valid_indices.append(i)\n",
        "        else:\n",
        "            valid_indices.append(i)\n",
        "\n",
        "    # Get top candidates\n",
        "    valid_scores = enhanced_scores[valid_indices]\n",
        "    num_candidates = min(k * 3, len(valid_indices))\n",
        "    top_candidate_local = valid_scores.argsort()[-num_candidates:][::-1]\n",
        "    top_candidates = [valid_indices[i] for i in top_candidate_local]\n",
        "\n",
        "    # Diversity selection\n",
        "    selected = []\n",
        "    selected_brands = set()\n",
        "\n",
        "    for idx in top_candidates:\n",
        "        if len(selected) >= k:\n",
        "            break\n",
        "\n",
        "        brand = products_df.iloc[idx]['brand']\n",
        "        brand_count = sum([1 for s in selected if products_df.iloc[s]['brand'] == brand])\n",
        "\n",
        "        if brand_count < 2:\n",
        "            selected.append(idx)\n",
        "            selected_brands.add(brand)\n",
        "\n",
        "    # Build results\n",
        "    results = []\n",
        "    for rank, idx in enumerate(selected, 1):\n",
        "        product_row = products_df.iloc[idx]\n",
        "\n",
        "        product_skin_types = [\n",
        "            st for st in ['Dry', 'Oily', 'Combination', 'Normal', 'Sensitive']\n",
        "            if product_row[st] == 1\n",
        "        ]\n",
        "\n",
        "        matches_query = any([st in product_skin_types for st in query_skin_types]) if query_skin_types else True\n",
        "\n",
        "        results.append({\n",
        "            'rank': rank,\n",
        "            'idx': idx,\n",
        "            'name': product_row['name'],\n",
        "            'brand': product_row['brand'],\n",
        "            'category': product_row['Label'],\n",
        "            'price': product_row['price'],\n",
        "            'rating': product_row['rank'],\n",
        "            'base_score': base_scores[idx],\n",
        "            'enhanced_score': enhanced_scores[idx],\n",
        "            'specificity': calculate_specificity_score(product_row),\n",
        "            'precision': calculate_match_precision(product_row, query_skin_types),\n",
        "            'skin_types': ', '.join(product_skin_types) if product_skin_types else 'Not specified',\n",
        "            'matches_query': matches_query,\n",
        "            'query_skin_types': ', '.join(query_skin_types) if query_skin_types else 'None detected'\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\" Neural network functions defined\")\n",
        "print(\"  * Base NN: Raw model predictions\")\n",
        "print(\"  * Enhanced NN: Specificity + precision adjustments\")\n",
        "print(\"  * Filtering: Optional removal of products without skin type data\")\n",
        "\n",
        "print(\"STEP 5: COMPARATIVE EVALUATION\")\n",
        "\n",
        "def evaluate_all_systems(query, k=5):\n",
        "    \"\"\"Compare all three systems on a single query.\"\"\"\n",
        "\n",
        "    # 1. Baseline\n",
        "    baseline_results = recommend_top_k_baseline(query, k=k)\n",
        "\n",
        "    # 2. Neural Network (Base)\n",
        "    nn_base_scores = get_nn_base_scores(query)\n",
        "    query_skin_types = extract_query_skin_types_nn(query)\n",
        "\n",
        "    # Get top k for base NN with diversity\n",
        "    top_candidates = nn_base_scores.argsort()[-k*3:][::-1]\n",
        "    nn_base_selected = []\n",
        "    selected_brands = set()\n",
        "\n",
        "    for idx in top_candidates:\n",
        "        if len(nn_base_selected) >= k:\n",
        "            break\n",
        "        brand = products_df.iloc[idx]['brand']\n",
        "        brand_count = sum([1 for i in nn_base_selected if products_df.iloc[i]['brand'] == brand])\n",
        "        if brand_count < 2:\n",
        "            nn_base_selected.append(idx)\n",
        "            selected_brands.add(brand)\n",
        "\n",
        "    nn_base_results = []\n",
        "    for rank, idx in enumerate(nn_base_selected, 1):\n",
        "        product_row = products_df.iloc[idx]\n",
        "        product_skin_types = [\n",
        "            st for st in ['Dry', 'Oily', 'Combination', 'Normal', 'Sensitive']\n",
        "            if product_row[st] == 1\n",
        "        ]\n",
        "        matches_query = any([st in product_skin_types for st in query_skin_types]) if query_skin_types else True\n",
        "\n",
        "        nn_base_results.append({\n",
        "            'rank': rank,\n",
        "            'idx': idx,\n",
        "            'name': product_row['name'],\n",
        "            'brand': product_row['brand'],\n",
        "            'final_score': nn_base_scores[idx],\n",
        "            'skin_types': ', '.join(product_skin_types) if product_skin_types else 'Not specified',\n",
        "            'matches_query': matches_query\n",
        "        })\n",
        "\n",
        "    # 3. Neural Network (Enhanced)\n",
        "    nn_enhanced_results = recommend_nn_enhanced(query, k=k, filter_no_skin_type=True)\n",
        "\n",
        "    return baseline_results, nn_base_results, nn_enhanced_results, query_skin_types\n",
        "\n",
        "\n",
        "def display_comparison(query, baseline_results, nn_base_results, nn_enhanced_results, query_skin_types):\n",
        "    \"\"\"Display side-by-side comparison of all three systems.\"\"\"\n",
        "\n",
        "    print(f\" QUERY: '{query}'\")\n",
        "    print(f\"Detected skin types: {', '.join(query_skin_types) if query_skin_types else 'None detected'}\")\n",
        "    print(f\"\\n{'='*80}\")\n",
        "\n",
        "    # Calculate match rates\n",
        "    baseline_matches = sum([1 for r in baseline_results if r['matches_query']])\n",
        "    nn_base_matches = sum([1 for r in nn_base_results if r['matches_query']])\n",
        "    nn_enhanced_matches = sum([1 for r in nn_enhanced_results if r['matches_query']])\n",
        "\n",
        "    k = len(baseline_results)\n",
        "\n",
        "    print(f\"\\n MATCH RATE COMPARISON:\")\n",
        "    print(f\"   Baseline:        {baseline_matches}/{k} ({baseline_matches/k*100:.0f}%)\")\n",
        "    print(f\"   NN Base:         {nn_base_matches}/{k} ({nn_base_matches/k*100:.0f}%)\")\n",
        "    print(f\"   NN Enhanced:     {nn_enhanced_matches}/{k} ({nn_enhanced_matches/k*100:.0f}%)\")\n",
        "\n",
        "    # Show top 3 from each\n",
        "    print(\"TOP 3 PRODUCTS FROM EACH SYSTEM:\")\n",
        "\n",
        "    for i in range(min(3, k)):\n",
        "        print(f\"Rank #{i+1}:\")\n",
        "        print(f\"{'─'*80}\")\n",
        "\n",
        "        # Baseline\n",
        "        b = baseline_results[i]\n",
        "        match_symbol = \"\" if b['matches_query'] else \"X\"\n",
        "        print(f\"  BASELINE {match_symbol}:\")\n",
        "        print(f\"    {b['name'][:60]}\")\n",
        "        print(f\"    {b['brand']} | {b['category']} | ${b['price']:.2f}\")\n",
        "        print(f\"    For: {b['skin_types']}\")\n",
        "        print(f\"    Score: {b['final_score']:.1%}\")\n",
        "\n",
        "        # NN Base\n",
        "        nb = nn_base_results[i]\n",
        "        match_symbol = \"✓\" if nb['matches_query'] else \"X\"\n",
        "        print(f\"\\n  NN BASE {match_symbol}:\")\n",
        "        print(f\"    {nb['name'][:60]}\")\n",
        "        print(f\"    {nb['brand']} | For: {nb['skin_types']}\")\n",
        "        print(f\"    Score: {nb['final_score']:.1%}\")\n",
        "\n",
        "        # NN Enhanced\n",
        "        ne = nn_enhanced_results[i]\n",
        "        match_symbol = \"✓\" if ne['matches_query'] else \"X\"\n",
        "        print(f\"\\n  NN ENHANCED {match_symbol}:\")\n",
        "        print(f\"    {ne['name'][:60]}\")\n",
        "        print(f\"    {ne['brand']} | For: {ne['skin_types']}\")\n",
        "        print(f\"    Base: {ne['base_score']:.1%} → Enhanced: {ne['enhanced_score']:.1%}\")\n",
        "        print(f\"    Specificity: {ne['specificity']:.1%} | Precision: {ne['precision']:.1%}\")\n",
        "\n",
        "        print()\n",
        "\n",
        "    return baseline_matches/k*100, nn_base_matches/k*100, nn_enhanced_matches/k*100\n",
        "\n",
        "\n",
        "# Run comparative evaluation\n",
        "print(\"\\n Running comparative evaluation on test queries...\\n\")\n",
        "\n",
        "test_queries = [\n",
        "    \"dry sensitive skin with redness\",\n",
        "    \"oily acne prone skin\",\n",
        "    \"combination skin with dark spots\",\n",
        "    \"mature skin with wrinkles\"\n",
        "]\n",
        "\n",
        "all_baseline_rates = []\n",
        "all_nn_base_rates = []\n",
        "all_nn_enhanced_rates = []\n",
        "\n",
        "for query in test_queries:\n",
        "    baseline_res, nn_base_res, nn_enhanced_res, query_st = evaluate_all_systems(query, k=5)\n",
        "    b_rate, nb_rate, ne_rate = display_comparison(query, baseline_res, nn_base_res, nn_enhanced_res, query_st)\n",
        "\n",
        "    all_baseline_rates.append(b_rate)\n",
        "    all_nn_base_rates.append(nb_rate)\n",
        "    all_nn_enhanced_rates.append(ne_rate)\n",
        "\n",
        "    print(\"\\n\" + \"─\"*80 + \"\\n\")\n",
        "\n",
        "print(\"FINAL EVALUATION SUMMARY\")\n",
        "\n",
        "avg_baseline = np.mean(all_baseline_rates)\n",
        "avg_nn_base = np.mean(all_nn_base_rates)\n",
        "avg_nn_enhanced = np.mean(all_nn_enhanced_rates)\n",
        "\n",
        "print(f\"\\n AVERAGE MATCH RATES:\")\n",
        "print(f\"   Baseline (Rule-based):         {avg_baseline:.1f}%\")\n",
        "print(f\"   Neural Network (Base):         {avg_nn_base:.1f}%\")\n",
        "print(f\"   Neural Network (Enhanced):     {avg_nn_enhanced:.1f}%\")\n",
        "\n",
        "print(f\"\\n IMPROVEMENTS:\")\n",
        "improvement_base = avg_nn_base - avg_baseline\n",
        "improvement_enhanced = avg_nn_enhanced - avg_baseline\n",
        "print(f\"   NN Base vs Baseline:           {improvement_base:+.1f} percentage points\")\n",
        "print(f\"   NN Enhanced vs Baseline:       {improvement_enhanced:+.1f} percentage points\")\n",
        "print(f\"   NN Enhanced vs NN Base:        {avg_nn_enhanced - avg_nn_base:+.1f} percentage points\")\n",
        "\n",
        "print(\"Verdict:\")\n",
        "\n",
        "if avg_nn_enhanced > avg_baseline + 5:\n",
        "    print(\" WINNER: Neural Network (Enhanced)\")\n",
        "    print(f\"   The enhanced neural network significantly outperforms the baseline\")\n",
        "    print(f\"   by {avg_nn_enhanced - avg_baseline:.1f} percentage points.\")\n",
        "    print(f\"   The training complexity is JUSTIFIED.\")\n",
        "elif avg_nn_enhanced > avg_baseline:\n",
        "    print(\" WINNER: Neural Network (Enhanced) - Marginal\")\n",
        "    print(f\"   The enhanced neural network slightly outperforms the baseline\")\n",
        "    print(f\"   by {avg_nn_enhanced - avg_baseline:.1f} percentage points.\")\n",
        "    print(f\"   Consider if the improvement justifies the added complexity.\")\n",
        "elif abs(avg_nn_enhanced - avg_baseline) <= 2:\n",
        "    print(\"  TIE: Both systems perform similarly\")\n",
        "    print(f\"   Difference is only {abs(avg_nn_enhanced - avg_baseline):.1f} percentage points.\")\n",
        "    print(f\"   The simpler baseline may be preferred for production.\")\n",
        "else:\n",
        "    print(\"  WINNER: Baseline\")\n",
        "    print(f\"   The baseline outperforms the neural network by {avg_baseline - avg_nn_enhanced:.1f} points.\")\n",
        "    print(f\"   The neural network training was NOT justified.\")\n",
        "\n",
        "print(f\"\\n KEY INSIGHTS:\")\n",
        "print(f\"   * Enhancement impact: {avg_nn_enhanced - avg_nn_base:+.1f} points\")\n",
        "if avg_nn_enhanced - avg_nn_base > 5:\n",
        "    print(f\"   * The specificity/precision enhancements provide significant value\")\n",
        "elif avg_nn_enhanced - avg_nn_base > 0:\n",
        "    print(f\"   * The specificity/precision enhancements provide modest value\")\n",
        "else:\n",
        "    print(f\"   * The specificity/precision enhancements have minimal impact\")\n",
        "\n",
        "print(f\"\\n   * Best system: \", end=\"\")\n",
        "if avg_nn_enhanced == max(avg_baseline, avg_nn_base, avg_nn_enhanced):\n",
        "    print(\"Neural Network (Enhanced)\")\n",
        "elif avg_nn_base == max(avg_baseline, avg_nn_base, avg_nn_enhanced):\n",
        "    print(\"Neural Network (Base)\")\n",
        "else:\n",
        "    print(\"Baseline\")"
      ],
      "metadata": {
        "id": "CE0oy-vLsq1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing why the 0% scores"
      ],
      "metadata": {
        "id": "TUsSUdMYvclR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n DIAGNOSTIC: Checking model outputs...\")\n",
        "test_query = \"dry sensitive skin\"\n",
        "query_emb = sbert_model.encode([test_query], normalize_embeddings=True)[0]\n",
        "\n",
        "# Check a few products\n",
        "for i in range(5):\n",
        "    product_emb = product_embeddings[i]\n",
        "    numerical = price_rank_features[i]\n",
        "    features = np.concatenate([query_emb, product_emb, numerical])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        score = model(torch.FloatTensor(features).unsqueeze(0).to(device))\n",
        "        print(f\"Product {i}: Score = {score.item():.6f}\")\n",
        "\n",
        "# Check feature statistics\n",
        "print(f\"\\nQuery embedding stats: mean={query_emb.mean():.3f}, std={query_emb.std():.3f}\")\n",
        "print(f\"Product embedding stats: mean={product_embeddings.mean():.3f}, std={product_embeddings.std():.3f}\")\n",
        "print(f\"Price stats: mean={price_rank_features[:, 0].mean():.3f}, std={price_rank_features[:, 0].std():.3f}\")\n",
        "print(f\"Rank stats: mean={price_rank_features[:, 1].mean():.3f}, std={price_rank_features[:, 1].std():.3f}\")"
      ],
      "metadata": {
        "id": "4XiWGzWNvjDg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}