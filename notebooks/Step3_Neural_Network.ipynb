{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Neural Network Training**\n",
        "\n",
        "Train a neural network classifier on top of Sentence-BERT embeddings"
      ],
      "metadata": {
        "id": "UCK3fOr4k9a9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "import os\n",
        "if os.path.exists('product_embeddings.npy'):\n",
        "       os.remove('product_embeddings.npy')\n",
        "if os.path.exists('query_embeddings_train.npy'):\n",
        "       os.remove('query_embeddings_train.npy')\n",
        "if os.path.exists('query_embeddings_val.npy'):\n",
        "       os.remove('query_embeddings_val.npy')\n",
        "if os.path.exists('query_embeddings_test.npy'):\n",
        "       os.remove('query_embeddings_test.npy')\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"\\n  Using device: {device}\")\n",
        "if device.type == 'cuda':\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")"
      ],
      "metadata": {
        "id": "eG2J5-OWoLkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameters**"
      ],
      "metadata": {
        "id": "n6BzsxcQoNIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHS = 20\n",
        "EARLY_STOPPING_PATIENCE = 5\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(RANDOM_SEED)\n",
        "\n",
        "print(f\"\\n  Hyperparameters:\")\n",
        "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"   Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"   Max Epochs: {NUM_EPOCHS}\")\n",
        "print(f\"   Early Stopping Patience: {EARLY_STOPPING_PATIENCE}\")"
      ],
      "metadata": {
        "id": "dwQvjxnBoNQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Data**"
      ],
      "metadata": {
        "id": "t1fCmWSHoNe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load products\n",
        "products_df = pd.read_csv('/content/drive/MyDrive/cosmetic_p.csv')\n",
        "print(f\"Loaded {len(products_df)} products\")\n",
        "\n",
        "# Load training pairs\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/training_pairs_train.csv')\n",
        "val_df = pd.read_csv('/content/drive/MyDrive/training_pairs_val.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/training_pairs_test.csv')\n",
        "\n",
        "print(f\"Loaded training data:\")\n",
        "print(f\"   Train: {len(train_df):,} pairs ({(train_df['label']==1).sum():,} positive)\")\n",
        "print(f\"   Val:   {len(val_df):,} pairs ({(val_df['label']==1).sum():,} positive)\")\n",
        "print(f\"   Test:  {len(test_df):,} pairs ({(test_df['label']==1).sum():,} positive)\")"
      ],
      "metadata": {
        "id": "hBQtiXYaoNnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate Sentence-Bert Embeddings**"
      ],
      "metadata": {
        "id": "JAxsCql2oNuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nLoading Sentence-BERT model...\")\n",
        "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"Model loaded: all-MiniLM-L6-v2 (384-dim embeddings)\")\n",
        "\n",
        "# Check if embeddings already exist\n",
        "import os\n",
        "if os.path.exists('product_embeddings.npy') and os.path.exists('query_embeddings_train.npy'):\n",
        "    print(\"\\nFound existing embeddings, loading...\")\n",
        "    product_embeddings = np.load('product_embeddings.npy')\n",
        "    query_embeddings_train = np.load('query_embeddings_train.npy')\n",
        "    query_embeddings_val = np.load('query_embeddings_val.npy')\n",
        "    query_embeddings_test = np.load('query_embeddings_test.npy')\n",
        "    print(\"Loaded embeddings from files\")\n",
        "else:\n",
        "    print(\"\\nGenerating embeddings (this may take 5-10 minutes)...\")\n",
        "\n",
        "    # Encode all products\n",
        "    print(\"\\n   Encoding products...\")\n",
        "    product_texts = products_df['ingredients'].fillna('').tolist()\n",
        "    product_embeddings = sbert_model.encode(\n",
        "        product_texts,\n",
        "        show_progress_bar=True,\n",
        "        batch_size=32,\n",
        "        normalize_embeddings=True\n",
        "    )\n",
        "\n",
        "    # Encode unique queries from each split\n",
        "    print(\"\\n   Encoding train queries...\")\n",
        "    train_queries = train_df['query'].unique()\n",
        "    query_embeddings_train = sbert_model.encode(\n",
        "        train_queries.tolist(),\n",
        "        show_progress_bar=True,\n",
        "        batch_size=32,\n",
        "        normalize_embeddings=True\n",
        "    )\n",
        "\n",
        "    print(\"\\n   Encoding val queries...\")\n",
        "    val_queries = val_df['query'].unique()\n",
        "    query_embeddings_val = sbert_model.encode(\n",
        "        val_queries.tolist(),\n",
        "        show_progress_bar=True,\n",
        "        batch_size=32,\n",
        "        normalize_embeddings=True\n",
        "    )\n",
        "\n",
        "    print(\"\\n   Encoding test queries...\")\n",
        "    test_queries = test_df['query'].unique()\n",
        "    query_embeddings_test = sbert_model.encode(\n",
        "        test_queries.tolist(),\n",
        "        show_progress_bar=True,\n",
        "        batch_size=32,\n",
        "        normalize_embeddings=True\n",
        "    )\n",
        "\n",
        "    # Save embeddings\n",
        "    np.save('product_embeddings.npy', product_embeddings)\n",
        "    np.save('query_embeddings_train.npy', query_embeddings_train)\n",
        "    np.save('query_embeddings_val.npy', query_embeddings_val)\n",
        "    np.save('query_embeddings_test.npy', query_embeddings_test)\n",
        "    print(\"\\nSaved embeddings to .npy files\")\n",
        "\n",
        "print(f\"\\nEmbeddings ready:\")\n",
        "print(f\"   Product embeddings: {product_embeddings.shape}\")\n",
        "print(f\"   Query embeddings (train): {query_embeddings_train.shape}\")\n",
        "print(f\"   Query embeddings (val): {query_embeddings_val.shape}\")\n",
        "print(f\"   Query embeddings (test): {query_embeddings_test.shape}\")\n",
        "\n",
        "# Create query-to-embedding mapping\n",
        "train_query_to_emb = dict(zip(train_df['query'].unique(), query_embeddings_train))\n",
        "val_query_to_emb = dict(zip(val_df['query'].unique(), query_embeddings_val))\n",
        "test_query_to_emb = dict(zip(test_df['query'].unique(), query_embeddings_test))"
      ],
      "metadata": {
        "id": "TeaAT_oboN1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare Numerical Features**"
      ],
      "metadata": {
        "id": "xyfxpxbnoOBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize price and rank\n",
        "scaler = StandardScaler()\n",
        "price_rank_features = scaler.fit_transform(\n",
        "    products_df[['price', 'rank']].fillna(0)\n",
        ")\n",
        "\n",
        "print(f\"Normalized price and rank features: {price_rank_features.shape}\")"
      ],
      "metadata": {
        "id": "SVBJeoMOoOHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch Dataseta"
      ],
      "metadata": {
        "id": "JG956otloON5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SkincareDataset(Dataset):\n",
        "    def __init__(self, df, query_to_emb, product_embeddings, price_rank_features):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.query_to_emb = query_to_emb\n",
        "        self.product_embeddings = product_embeddings\n",
        "        self.price_rank_features = price_rank_features\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        # Get query embedding\n",
        "        query_emb = self.query_to_emb[row['query']]\n",
        "\n",
        "        # Get product embedding\n",
        "        product_emb = self.product_embeddings[row['product_id']]\n",
        "\n",
        "        # Get numerical features\n",
        "        numerical = self.price_rank_features[row['product_id']]\n",
        "\n",
        "        # Concatenate all features\n",
        "        features = np.concatenate([query_emb, product_emb, numerical])\n",
        "\n",
        "        # Label\n",
        "        label = float(row['label'])\n",
        "\n",
        "        return torch.FloatTensor(features), torch.FloatTensor([label])\n",
        "\n",
        "# Create datasets\n",
        "print(\"\\nCreating PyTorch datasets...\")\n",
        "train_dataset = SkincareDataset(train_df, train_query_to_emb, product_embeddings, price_rank_features)\n",
        "val_dataset = SkincareDataset(val_df, val_query_to_emb, product_embeddings, price_rank_features)\n",
        "test_dataset = SkincareDataset(test_df, test_query_to_emb, product_embeddings, price_rank_features)\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"Created dataloaders:\")\n",
        "print(f\"   Train batches: {len(train_loader)}\")\n",
        "print(f\"   Val batches:   {len(val_loader)}\")\n",
        "print(f\"   Test batches:  {len(test_loader)}\")"
      ],
      "metadata": {
        "id": "vKebfK-4oOTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Neural Network Model**"
      ],
      "metadata": {
        "id": "X2OvtwCEpUeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SkincareMatchingNetwork(nn.Module):\n",
        "    def __init__(self, input_dim=770):  # 384 + 384 + 2 = 770\n",
        "        super(SkincareMatchingNetwork, self).__init__()\n",
        "\n",
        "        self.network = nn.Sequential(\n",
        "            # Layer 1\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            # Layer 2\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            # Layer 3\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            # Output layer\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "# Initialize model\n",
        "model = SkincareMatchingNetwork().to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"MODEL ARCHITECTURE\")\n",
        "print(f\"\\n{model}\\n\")\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.5, patience=3\n",
        ")\n"
      ],
      "metadata": {
        "id": "McNak6YspUmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Functions**"
      ],
      "metadata": {
        "id": "UD0CuvgppUui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for features, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        features, labels = features.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Store predictions\n",
        "        all_preds.extend((outputs > 0.5).cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for features, labels in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(features)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            all_probs.extend(outputs.cpu().numpy())\n",
        "            all_preds.extend((outputs > 0.5).cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "\n",
        "    # Calculate metrics\n",
        "    all_preds = np.array(all_preds).flatten()\n",
        "    all_labels = np.array(all_labels).flatten()\n",
        "    all_probs = np.array(all_probs).flatten()\n",
        "\n",
        "    accuracy = np.mean(all_preds == all_labels)\n",
        "    precision = precision_score(all_labels, all_preds, zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
        "\n",
        "    try:\n",
        "        auc = roc_auc_score(all_labels, all_probs)\n",
        "    except:\n",
        "        auc = 0.0\n",
        "\n",
        "    return avg_loss, accuracy, precision, recall, f1, auc"
      ],
      "metadata": {
        "id": "6sUTNtWYpU1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Loop**"
      ],
      "metadata": {
        "id": "CoTYP9KepU8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training history\n",
        "history = {\n",
        "    'train_loss': [],\n",
        "    'train_acc': [],\n",
        "    'val_loss': [],\n",
        "    'val_acc': [],\n",
        "    'val_precision': [],\n",
        "    'val_recall': [],\n",
        "    'val_f1': [],\n",
        "    'val_auc': []\n",
        "}\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "best_model_state = None\n",
        "\n",
        "print(f\"\\nStarting training for {NUM_EPOCHS} epochs...\\n\")\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # Train\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "\n",
        "    # Validate\n",
        "    val_loss, val_acc, val_prec, val_rec, val_f1, val_auc = evaluate(\n",
        "        model, val_loader, criterion, device\n",
        "    )\n",
        "\n",
        "    # Store history\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_precision'].append(val_prec)\n",
        "    history['val_recall'].append(val_rec)\n",
        "    history['val_f1'].append(val_f1)\n",
        "    history['val_auc'].append(val_auc)\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "    print(f\"Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.4f}\")\n",
        "    print(f\"Val Prec:   {val_prec:.4f} | Val Rec:   {val_rec:.4f} | Val F1: {val_f1:.4f}\")\n",
        "    print(f\"Val AUC:    {val_auc:.4f}\")\n",
        "\n",
        "    # Learning rate scheduling\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Early stopping\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        best_model_state = model.state_dict().copy()\n",
        "        print(\"New best model saved!\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\" No improvement ({patience_counter}/{EARLY_STOPPING_PATIENCE})\")\n",
        "\n",
        "    print()\n",
        "\n",
        "    if patience_counter >= EARLY_STOPPING_PATIENCE:\n",
        "        print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
        "        break\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(best_model_state)\n",
        "print(\"\\nLoaded best model from training\")\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), 'skincare_model.pth')\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'history': history,\n",
        "    'hyperparameters': {\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'learning_rate': LEARNING_RATE,\n",
        "        'num_epochs': epoch+1\n",
        "    }\n",
        "}, 'skincare_model_full.pth')\n",
        "\n",
        "print(\"Saved model to:\")\n",
        "print(\"   - skincare_model.pth (weights only)\")\n",
        "print(\"   - skincare_model_full.pth (full checkpoint)\")"
      ],
      "metadata": {
        "id": "0CVlglFTpVDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test Set Evaluation**"
      ],
      "metadata": {
        "id": "2Sq3rkYEpVLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc, test_prec, test_rec, test_f1, test_auc = evaluate(\n",
        "    model, test_loader, criterion, device\n",
        ")\n",
        "\n",
        "print(f\"\\nTest Set Results:\")\n",
        "print(f\"   Loss:      {test_loss:.4f}\")\n",
        "print(f\"   Accuracy:  {test_acc:.4f}\")\n",
        "print(f\"   Precision: {test_prec:.4f}\")\n",
        "print(f\"   Recall:    {test_rec:.4f}\")\n",
        "print(f\"   F1 Score:  {test_f1:.4f}\")\n",
        "print(f\"   AUC-ROC:   {test_auc:.4f}\")"
      ],
      "metadata": {
        "id": "yOk_O60DpVRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizations"
      ],
      "metadata": {
        "id": "f5VnLuwfppqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCreating visualizations...\")\n",
        "\n",
        "fig = plt.figure(figsize=(16, 10))\n",
        "gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
        "\n",
        "# 1. Training & Validation Loss\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "epochs_range = range(1, len(history['train_loss']) + 1)\n",
        "ax1.plot(epochs_range, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
        "ax1.plot(epochs_range, history['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('Training & Validation Loss', fontweight='bold')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Training & Validation Accuracy\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "ax2.plot(epochs_range, history['train_acc'], 'b-', label='Train Acc', linewidth=2)\n",
        "ax2.plot(epochs_range, history['val_acc'], 'r-', label='Val Acc', linewidth=2)\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.set_title('Training & Validation Accuracy', fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Validation Metrics Over Time\n",
        "ax3 = fig.add_subplot(gs[1, :])\n",
        "ax3.plot(epochs_range, history['val_precision'], label='Precision', linewidth=2)\n",
        "ax3.plot(epochs_range, history['val_recall'], label='Recall', linewidth=2)\n",
        "ax3.plot(epochs_range, history['val_f1'], label='F1 Score', linewidth=2)\n",
        "ax3.plot(epochs_range, history['val_auc'], label='AUC-ROC', linewidth=2)\n",
        "ax3.set_xlabel('Epoch')\n",
        "ax3.set_ylabel('Score')\n",
        "ax3.set_title('Validation Metrics Over Time', fontweight='bold')\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Final Test Metrics Bar Chart\n",
        "ax4 = fig.add_subplot(gs[2, 0])\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1', 'AUC']\n",
        "values = [test_acc, test_prec, test_rec, test_f1, test_auc]\n",
        "colors = ['#3498db', '#2ecc71', '#e74c3c', '#f39c12', '#9b59b6']\n",
        "bars = ax4.bar(metrics, values, color=colors, alpha=0.7)\n",
        "ax4.set_ylabel('Score')\n",
        "ax4.set_title('Test Set Performance', fontweight='bold')\n",
        "ax4.set_ylim(0, 1)\n",
        "ax4.grid(axis='y', alpha=0.3)\n",
        "for bar, val in zip(bars, values):\n",
        "    ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
        "             f'{val:.3f}', ha='center', fontweight='bold')\n",
        "\n",
        "# 5. Training Summary Table\n",
        "ax5 = fig.add_subplot(gs[2, 1])\n",
        "ax5.axis('off')\n",
        "summary_data = [\n",
        "    ['Metric', 'Value'],\n",
        "    ['Total Epochs', f\"{len(history['train_loss'])}\"],\n",
        "    ['Best Val Loss', f\"{best_val_loss:.4f}\"],\n",
        "    ['Final Train Loss', f\"{history['train_loss'][-1]:.4f}\"],\n",
        "    ['Final Val Loss', f\"{history['val_loss'][-1]:.4f}\"],\n",
        "    ['Test Accuracy', f\"{test_acc:.4f}\"],\n",
        "    ['Test F1 Score', f\"{test_f1:.4f}\"],\n",
        "    ['Parameters', f\"{trainable_params:,}\"]\n",
        "]\n",
        "table = ax5.table(cellText=summary_data, cellLoc='left', loc='center',\n",
        "                  colWidths=[0.5, 0.5])\n",
        "table.auto_set_font_size(False)\n",
        "table.set_fontsize(10)\n",
        "table.scale(1, 2)\n",
        "for i in range(len(summary_data)):\n",
        "    if i == 0:\n",
        "        table[(i, 0)].set_facecolor('#3498db')\n",
        "        table[(i, 1)].set_facecolor('#3498db')\n",
        "        table[(i, 0)].set_text_props(weight='bold', color='white')\n",
        "        table[(i, 1)].set_text_props(weight='bold', color='white')\n",
        "\n",
        "plt.savefig('training_results.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved: training_results.png\")"
      ],
      "metadata": {
        "id": "T0FY-vbwppyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary**"
      ],
      "metadata": {
        "id": "yHOebDCcpp45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\"\"\n",
        "Final results:\n",
        "\n",
        "Training:\n",
        "  * Epochs trained: {len(history['train_loss'])}\n",
        "  * Best val loss: {best_val_loss:.4f}\n",
        "  * Final train loss: {history['train_loss'][-1]:.4f}\n",
        "  * Final train acc: {history['train_acc'][-1]:.4f}\n",
        "\n",
        "Test Performance:\n",
        "  * Accuracy:  {test_acc:.4f}\n",
        "  * Precision: {test_prec:.4f}\n",
        "  * Recall:    {test_rec:.4f}\n",
        "  * F1 Score:  {test_f1:.4f}\n",
        "  * AUC-ROC:   {test_auc:.4f}\n",
        "\n",
        "Model:\n",
        "  * Architecture: 4-layer neural network\n",
        "  • Parameters: {trainable_params:,}\n",
        "  * Input: Sentence-BERT embeddings (384×2) + numerical (2)\n",
        "  * Output: Binary compatibility score\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "rtHk-o-spqAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Interactive Demo**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "nI7AjEdzyVgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "vPtp7kdUyVoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Model and Data**"
      ],
      "metadata": {
        "id": "rS2-zZ-oyVww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nLoading model and data...\")\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load products\n",
        "products_df = pd.read_csv('/content/drive/MyDrive/cosmetic_p.csv')\n",
        "\n",
        "# Load embeddings\n",
        "product_embeddings = np.load('product_embeddings.npy')\n",
        "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Prepare scaler for numerical features\n",
        "scaler = StandardScaler()\n",
        "price_rank_features = scaler.fit_transform(\n",
        "    products_df[['price', 'rank']].fillna(0)\n",
        ")\n",
        "\n",
        "# Define model architecture\n",
        "class SkincareMatchingNetwork(nn.Module):\n",
        "    def __init__(self, input_dim=770):\n",
        "        super(SkincareMatchingNetwork, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "# Load trained model\n",
        "model = SkincareMatchingNetwork().to(device)\n",
        "model.load_state_dict(torch.load('skincare_model.pth', map_location=device))\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded successfully\")\n",
        "print(f\"Loaded {len(products_df)} products\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "t1Z8hO73yV5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recommendation Functions"
      ],
      "metadata": {
        "id": "9_pGoQD2yWCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_compatibility_scores(query):\n",
        "    \"\"\"\n",
        "    Get compatibility scores for all products given a query.\n",
        "    Returns: array of scores (one per product)\n",
        "    \"\"\"\n",
        "    # Encode query\n",
        "    query_emb = sbert_model.encode([query], normalize_embeddings=True)[0]\n",
        "\n",
        "    # Prepare features for all products\n",
        "    batch_features = []\n",
        "    for i in range(len(products_df)):\n",
        "        product_emb = product_embeddings[i]\n",
        "        numerical = price_rank_features[i]\n",
        "        features = np.concatenate([query_emb, product_emb, numerical])\n",
        "        batch_features.append(features)\n",
        "\n",
        "    # Convert to tensor\n",
        "    batch_tensor = torch.FloatTensor(np.array(batch_features)).to(device)\n",
        "\n",
        "    # Get predictions\n",
        "    with torch.no_grad():\n",
        "        scores = model(batch_tensor).cpu().numpy().flatten()\n",
        "\n",
        "    return scores\n",
        "\n",
        "def recommend_top_k(query, k=5):\n",
        "    \"\"\"\n",
        "    Recommend top-K products for a query.\n",
        "    \"\"\"\n",
        "    scores = get_compatibility_scores(query)\n",
        "\n",
        "    # Get top K indices\n",
        "    top_indices = scores.argsort()[-k:][::-1]\n",
        "\n",
        "    # Build results\n",
        "    results = []\n",
        "    for idx in top_indices:\n",
        "        results.append({\n",
        "            'rank': len(results) + 1,\n",
        "            'name': products_df.iloc[idx]['name'],\n",
        "            'brand': products_df.iloc[idx]['brand'],\n",
        "            'category': products_df.iloc[idx]['Label'],\n",
        "            'price': products_df.iloc[idx]['price'],\n",
        "            'rating': products_df.iloc[idx]['rank'],\n",
        "            'compatibility_score': scores[idx],\n",
        "            'skin_types': ', '.join([\n",
        "                st for st in ['Dry', 'Oily', 'Combination', 'Normal', 'Sensitive']\n",
        "                if products_df.iloc[idx][st] == 1\n",
        "            ])\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "def recommend_routine(query):\n",
        "    \"\"\"\n",
        "    Build a complete skincare routine (one product per category).\n",
        "    \"\"\"\n",
        "    scores = get_compatibility_scores(query)\n",
        "\n",
        "    # Define routine categories in order\n",
        "    routine_categories = [\n",
        "        'Cleanser',\n",
        "        'Treatment',\n",
        "        'Eye cream',\n",
        "        'Moisturizer',\n",
        "        'Sun protect',\n",
        "        'Face Mask'\n",
        "    ]\n",
        "\n",
        "    routine = {}\n",
        "\n",
        "    for category in routine_categories:\n",
        "        # Filter products by category\n",
        "        category_mask = products_df['Label'] == category\n",
        "        category_indices = products_df[category_mask].index.tolist()\n",
        "\n",
        "        if len(category_indices) == 0:\n",
        "            continue\n",
        "\n",
        "        # Get scores for this category\n",
        "        category_scores = scores[category_indices]\n",
        "\n",
        "        # Get best product\n",
        "        best_local_idx = category_scores.argmax()\n",
        "        best_global_idx = category_indices[best_local_idx]\n",
        "\n",
        "        routine[category] = {\n",
        "            'name': products_df.iloc[best_global_idx]['name'],\n",
        "            'brand': products_df.iloc[best_global_idx]['brand'],\n",
        "            'price': products_df.iloc[best_global_idx]['price'],\n",
        "            'rating': products_df.iloc[best_global_idx]['rank'],\n",
        "            'compatibility_score': scores[best_global_idx],\n",
        "            'skin_types': ', '.join([\n",
        "                st for st in ['Dry', 'Oily', 'Combination', 'Normal', 'Sensitive']\n",
        "                if products_df.iloc[best_global_idx][st] == 1\n",
        "            ])\n",
        "        }\n",
        "\n",
        "    return routine"
      ],
      "metadata": {
        "id": "LtW-HjHbyWIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interactive Demo**"
      ],
      "metadata": {
        "id": "Rqj4NzYfyWPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_top_k_results(results, query):\n",
        "    \"\"\"Display top-K recommendations in a nice format.\"\"\"\n",
        "    print(f\"QUERY: '{query}'\")\n",
        "    print(f\"TOP {len(results)} RECOMMENDATIONS:\\n\")\n",
        "\n",
        "    for r in results:\n",
        "        print(f\"#{r['rank']}. {r['name']}\")\n",
        "        print(f\"    Brand:        {r['brand']}\")\n",
        "        print(f\"    Category:     {r['category']}\")\n",
        "        print(f\"    Price:        ${r['price']:.2f}\")\n",
        "        print(f\"    Rating:       {r['rating']:.1f}/5.0\")\n",
        "        print(f\"    Match Score:  {r['compatibility_score']:.1%} \")\n",
        "        print(f\"    For:          {r['skin_types']}\")\n",
        "        print()\n",
        "\n",
        "def display_routine(routine, query):\n",
        "    \"\"\"Display routine recommendations in a nice format.\"\"\"\n",
        "    print(f\"QUERY: '{query}'\")\n",
        "    print(f\"YOUR PERSONALIZED SKINCARE ROUTINE \\n\")\n",
        "\n",
        "    step = 1\n",
        "    for category, product in routine.items():\n",
        "        print(f\"STEP {step}: {category.upper()}\")\n",
        "        print(f\"  -> {product['name']}\")\n",
        "        print(f\"     By {product['brand']} | ${product['price']:.2f} |  {product['rating']:.1f}\")\n",
        "        print(f\"     Match: {product['compatibility_score']:.1%} | For: {product['skin_types']}\")\n",
        "        print()\n",
        "        step += 1\n",
        "\n",
        "    total_cost = sum(p['price'] for p in routine.values())\n",
        "    avg_score = np.mean([p['compatibility_score'] for p in routine.values()])\n",
        "    print(f\" Total Routine Cost: ${total_cost:.2f}\")\n",
        "    print(f\" Average Compatibility: {avg_score:.1%}\")\n"
      ],
      "metadata": {
        "id": "kI6ejWBIyWXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test Queries**"
      ],
      "metadata": {
        "id": "MbP3Yts7yWgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"DEMO: TESTING WITH SAMPLE QUERIES\")\n",
        "\n",
        "# Sample queries\n",
        "test_queries = [\n",
        "    \"I have dry sensitive skin with redness\",\n",
        "    \"oily skin with acne and large pores\",\n",
        "    \"anti aging products for mature skin\",\n",
        "    \"combination skin with occasional breakouts\"\n",
        "]\n",
        "\n",
        "# Mode 1: Top-K Recommendations\n",
        "print(\"MODE 1: TOP-K RECOMMENDATIONS\")\n",
        "\n",
        "for query in test_queries[:2]:  # Show 2 examples\n",
        "    results = recommend_top_k(query, k=5)\n",
        "    display_top_k_results(results, query)\n",
        "    input(\"Press Enter to continue...\")\n",
        "\n",
        "# Mode 2: Full Routine\n",
        "print(\"MODE 2: FULL SKINCARE ROUTINE\")\n",
        "\n",
        "for query in test_queries[2:3]:  # Show 1 example\n",
        "    routine = recommend_routine(query)\n",
        "    display_routine(routine, query)\n",
        "    input(\"Press Enter to continue...\")"
      ],
      "metadata": {
        "id": "M50b06pkyWn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interactive Mode**"
      ],
      "metadata": {
        "id": "_m7Kq-dmyWus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"INTERACTIVE MODE - you can try your own queries\")\n",
        "\n",
        "def interactive_session():\n",
        "    print(\"\\nYou can now test the model with your own queries!\")\n",
        "    print(\"Commands:\")\n",
        "    print(\"  - Type a skincare concern (e.g., 'dry skin with acne')\")\n",
        "    print(\"  - Type 'routine' before your query for a full routine\")\n",
        "    print(\"  - Type 'quit' to exit\")\n",
        "    print()\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\" Enter query (or 'quit'): \").strip()\n",
        "\n",
        "        if user_input.lower() == 'quit':\n",
        "            print(\"\\n Thanks for using the demo!\")\n",
        "            break\n",
        "\n",
        "        if not user_input:\n",
        "            continue\n",
        "\n",
        "        # Check if user wants routine\n",
        "        if user_input.lower().startswith('routine'):\n",
        "            query = user_input[7:].strip()\n",
        "            if not query:\n",
        "                query = input(\"   Enter your skin concerns: \").strip()\n",
        "            routine = recommend_routine(query)\n",
        "            display_routine(routine, query)\n",
        "        else:\n",
        "            query = user_input\n",
        "            k = 5\n",
        "            results = recommend_top_k(query, k=k)\n",
        "            display_top_k_results(results, query)\n",
        "\n",
        "        print()\n",
        "\n",
        "# Start interactive mode\n",
        "interactive_session()"
      ],
      "metadata": {
        "id": "ikel_5pNyW1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Diagnose current model to confirm what's actually wrong before making changes"
      ],
      "metadata": {
        "id": "l42tSncD3hxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"MODEL DIAGNOSTICS - checking for issues\")\n",
        "\n",
        "model.eval()\n",
        "all_scores = []\n",
        "\n",
        "# Test on a few different queries\n",
        "test_queries = [\n",
        "    \"dry sensitive skin\",\n",
        "    \"oily acne prone\",\n",
        "    \"anti aging wrinkles\",\n",
        "    \"combination skin\"\n",
        "]\n",
        "\n",
        "print(\"\\nGetting scores for different queries...\\n\")\n",
        "for query in test_queries:\n",
        "    query_emb = sbert_model.encode([query], normalize_embeddings=True)[0]\n",
        "\n",
        "    # Get scores for all products\n",
        "    batch_features = []\n",
        "    for i in range(len(products_df)):\n",
        "        product_emb = product_embeddings[i]\n",
        "        numerical = price_rank_features[i]\n",
        "        features = np.concatenate([query_emb, product_emb, numerical])\n",
        "        batch_features.append(features)\n",
        "\n",
        "    batch_tensor = torch.FloatTensor(np.array(batch_features)).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        scores = model(batch_tensor).cpu().numpy().flatten()\n",
        "\n",
        "    all_scores.extend(scores)\n",
        "\n",
        "    print(f\"Query: '{query}'\")\n",
        "    print(f\"  Min: {scores.min():.4f} | Max: {scores.max():.4f} | Mean: {scores.mean():.4f} | Std: {scores.std():.4f}\")\n",
        "    print(f\"  Scores > 0.9: {(scores > 0.9).sum()}/{len(scores)}\")\n",
        "\n",
        "all_scores = np.array(all_scores)\n",
        "\n",
        "print(\"OVERALL SCORE DISTRIBUTION:\")\n",
        "print(f\"Min:     {all_scores.min():.6f}\")\n",
        "print(f\"Max:     {all_scores.max():.6f}\")\n",
        "print(f\"Mean:    {all_scores.mean():.6f}\")\n",
        "print(f\"Std Dev: {all_scores.std():.6f}\")\n",
        "print(f\"\\nScores in ranges:\")\n",
        "print(f\"  [0.0-0.2]: {(all_scores < 0.2).sum():,} ({(all_scores < 0.2).sum()/len(all_scores)*100:.1f}%)\")\n",
        "print(f\"  [0.2-0.4]: {((all_scores >= 0.2) & (all_scores < 0.4)).sum():,} ({((all_scores >= 0.2) & (all_scores < 0.4)).sum()/len(all_scores)*100:.1f}%)\")\n",
        "print(f\"  [0.4-0.6]: {((all_scores >= 0.4) & (all_scores < 0.6)).sum():,} ({((all_scores >= 0.4) & (all_scores < 0.6)).sum()/len(all_scores)*100:.1f}%)\")\n",
        "print(f\"  [0.6-0.8]: {((all_scores >= 0.6) & (all_scores < 0.8)).sum():,} ({((all_scores >= 0.6) & (all_scores < 0.8)).sum()/len(all_scores)*100:.1f}%)\")\n",
        "print(f\"  [0.8-1.0]: {(all_scores >= 0.8).sum():,} ({(all_scores >= 0.8).sum()/len(all_scores)*100:.1f}%)\")\n",
        "\n",
        "if all_scores.std() < 0.01:\n",
        "    print(f\"\\n PROBLEM CONFIRMED: Model is saturated!\")\n",
        "    print(f\"   All predictions are nearly identical (std = {all_scores.std():.6f})\")\n",
        "    print(f\"\\n   Root cause: Training data likely has too many positive examples\")\n",
        "elif all_scores.std() < 0.1:\n",
        "    print(f\"\\n  WARNING: Low variance in predictions (std = {all_scores.std():.4f})\")\n",
        "    print(f\"   Model may not be discriminating well between products\")\n",
        "else:\n",
        "    print(f\"\\n Model variance looks reasonable (std = {all_scores.std():.4f})\")\n",
        "\n",
        "# Also check training data balance\n",
        "print(\"TRAINING DATA BALANCE CHECK:\")\n",
        "print(f\"Positive samples: {(train_df['label']==1).sum():,} ({(train_df['label']==1).sum()/len(train_df)*100:.1f}%)\")\n",
        "print(f\"Negative samples: {(train_df['label']==0).sum():,} ({(train_df['label']==0).sum()/len(train_df)*100:.1f}%)\")\n",
        "\n",
        "if (train_df['label']==1).sum() / len(train_df) > 0.7:\n",
        "    print(f\"\\n PROBLEM: Training data is heavily imbalanced toward positives!\")\n",
        "    print(f\"   This causes the model to predict 'match' for everything\")"
      ],
      "metadata": {
        "id": "cKYoSDxv3hYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TESTING: See which products keep winning since model repeats products regularly"
      ],
      "metadata": {
        "id": "W7EX39zyNKr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see which products keep winning\n",
        "print(\"Proudcts that always score high\")\n",
        "\n",
        "# Get scores for a test query\n",
        "test_query = \"dry sensitive skin\"\n",
        "query_emb = sbert_model.encode([test_query], normalize_embeddings=True)[0]\n",
        "\n",
        "batch_features = []\n",
        "for i in range(len(products_df)):\n",
        "    product_emb = product_embeddings[i]\n",
        "    numerical = price_rank_features[i]\n",
        "    features = np.concatenate([query_emb, product_emb, numerical])\n",
        "    batch_features.append(features)\n",
        "\n",
        "batch_tensor = torch.FloatTensor(np.array(batch_features)).to(device)\n",
        "with torch.no_grad():\n",
        "    scores = model(batch_tensor).cpu().numpy().flatten()\n",
        "\n",
        "# Get top 20 products\n",
        "top_20_idx = scores.argsort()[-20:][::-1]\n",
        "\n",
        "print(f\"\\nTop 20 products for '{test_query}':\\n\")\n",
        "for rank, idx in enumerate(top_20_idx, 1):\n",
        "    row = products_df.iloc[idx]\n",
        "    skin_types = [st for st in ['Dry', 'Oily', 'Combination', 'Normal', 'Sensitive'] if row[st] == 1]\n",
        "    print(f\"{rank:2}. Score: {scores[idx]:.4f} | {row['name'][:50]}\")\n",
        "    print(f\"    Skin: {', '.join(skin_types)} | Category: {row['Label']}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "ycJN58We3zac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SOLUTION WITH PENALTIES FOR GENERIC PRODUCTS"
      ],
      "metadata": {
        "id": "1xs9yEXqNUO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def calculate_specificity_score(product_row):\n",
        "    \"\"\"\n",
        "    Calculate how specific a product is (fewer skin types = more specific).\n",
        "    Returns a score between 0 (generic) and 1 (highly specific).\n",
        "    \"\"\"\n",
        "    skin_type_cols = ['Dry', 'Oily', 'Combination', 'Normal', 'Sensitive']\n",
        "    num_skin_types = sum([product_row[col] for col in skin_type_cols])\n",
        "\n",
        "    # Convert to specificity score\n",
        "    # 1 skin type = 1.0 (most specific)\n",
        "    # 5 skin types = 0.2 (least specific/generic)\n",
        "    specificity = 1.0 - (num_skin_types - 1) / 4.0\n",
        "\n",
        "    return specificity\n",
        "\n",
        "\n",
        "def extract_query_skin_types(query):\n",
        "    \"\"\"\n",
        "    Extract mentioned skin types from the query text.\n",
        "    Returns list of detected skin types.\n",
        "    \"\"\"\n",
        "    query_lower = query.lower()\n",
        "    detected = []\n",
        "\n",
        "    skin_type_keywords = {\n",
        "        'Dry': ['dry', 'dehydrated', 'flaky', 'tight'],\n",
        "        'Oily': ['oily', 'greasy', 'shiny', 'sebum'],\n",
        "        'Combination': ['combination', 'combo', 't-zone'],\n",
        "        'Normal': ['normal', 'balanced'],\n",
        "        'Sensitive': ['sensitive', 'reactive', 'redness', 'irritated']\n",
        "    }\n",
        "\n",
        "    for skin_type, keywords in skin_type_keywords.items():\n",
        "        if any(kw in query_lower for kw in keywords):\n",
        "            detected.append(skin_type)\n",
        "\n",
        "    return detected if detected else ['Normal']  # Default if none detected\n",
        "\n",
        "\n",
        "def calculate_match_precision(product_row, query_skin_types):\n",
        "    \"\"\"\n",
        "    Calculate how precisely a product matches the query's skin types.\n",
        "    Returns score between 0 and 1.\n",
        "    \"\"\"\n",
        "    if not query_skin_types:\n",
        "        return 0.5  # Neutral if no skin types specified\n",
        "\n",
        "    product_skin_types = [\n",
        "        st for st in ['Dry', 'Oily', 'Combination', 'Normal', 'Sensitive']\n",
        "        if product_row[st] == 1\n",
        "    ]\n",
        "\n",
        "    # Calculate overlap\n",
        "    matches = sum([1 for st in query_skin_types if st in product_skin_types])\n",
        "    precision = matches / len(query_skin_types)\n",
        "\n",
        "    # Bonus for exact match (no extra skin types)\n",
        "    if set(query_skin_types) == set(product_skin_types):\n",
        "        precision += 0.2\n",
        "\n",
        "    return min(precision, 1.0)\n",
        "\n",
        "\n",
        "def get_reranked_scores(query, model, sbert_model, products_df,\n",
        "                       product_embeddings, price_rank_features, device,\n",
        "                       specificity_weight=0.3, precision_weight=0.2):\n",
        "    \"\"\"\n",
        "    Get compatibility scores with specificity and precision adjustments.\n",
        "\n",
        "    Parameters:\n",
        "    - specificity_weight: How much to penalize generic products (0-1)\n",
        "    - precision_weight: How much to reward precise matches (0-1)\n",
        "    \"\"\"\n",
        "    # Get base model scores\n",
        "    query_emb = sbert_model.encode([query], normalize_embeddings=True)[0]\n",
        "\n",
        "    batch_features = []\n",
        "    for i in range(len(products_df)):\n",
        "        product_emb = product_embeddings[i]\n",
        "        numerical = price_rank_features[i]\n",
        "        features = np.concatenate([query_emb, product_emb, numerical])\n",
        "        batch_features.append(features)\n",
        "\n",
        "    batch_tensor = torch.FloatTensor(np.array(batch_features)).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        base_scores = model(batch_tensor).cpu().numpy().flatten()\n",
        "\n",
        "    # Extract query skin types\n",
        "    query_skin_types = extract_query_skin_types(query)\n",
        "\n",
        "    # Calculate adjusted scores\n",
        "    adjusted_scores = base_scores.copy()\n",
        "\n",
        "    for i in range(len(products_df)):\n",
        "        product_row = products_df.iloc[i]\n",
        "\n",
        "        # Calculate specificity bonus\n",
        "        specificity = calculate_specificity_score(product_row)\n",
        "\n",
        "        # Calculate precision bonus\n",
        "        precision = calculate_match_precision(product_row, query_skin_types)\n",
        "\n",
        "        # Combine scores\n",
        "        # Base score weighted by specificity and precision\n",
        "        adjusted_scores[i] = (\n",
        "            base_scores[i] * (1.0 + specificity * specificity_weight) *\n",
        "            (1.0 + precision * precision_weight)\n",
        "        )\n",
        "\n",
        "    # Normalize to 0-1 range\n",
        "    if adjusted_scores.max() > 0:\n",
        "        adjusted_scores = adjusted_scores / adjusted_scores.max()\n",
        "\n",
        "    return adjusted_scores, base_scores, query_skin_types\n",
        "\n",
        "\n",
        "def recommend_top_k_improved(query, model, sbert_model, products_df,\n",
        "                            product_embeddings, price_rank_features, device,\n",
        "                            k=5, specificity_weight=0.3, precision_weight=0.2,\n",
        "                            diversity_penalty=0.15):\n",
        "    \"\"\"\n",
        "    Improved recommendation with specificity awareness and diversity.\n",
        "    \"\"\"\n",
        "    adjusted_scores, base_scores, query_skin_types = get_reranked_scores(\n",
        "        query, model, sbert_model, products_df,\n",
        "        product_embeddings, price_rank_features, device,\n",
        "        specificity_weight, precision_weight\n",
        "    )\n",
        "\n",
        "    # Get top candidates (2x what I need for diversity selection)\n",
        "    num_candidates = min(k * 3, len(products_df))\n",
        "    top_candidates_idx = adjusted_scores.argsort()[-num_candidates:][::-1]\n",
        "\n",
        "    # Select diverse set\n",
        "    selected = []\n",
        "    selected_categories = set()\n",
        "    selected_brands = set()\n",
        "\n",
        "    for idx in top_candidates_idx:\n",
        "        if len(selected) >= k:\n",
        "            break\n",
        "\n",
        "        category = products_df.iloc[idx]['Label']\n",
        "        brand = products_df.iloc[idx]['brand']\n",
        "\n",
        "        # Apply diversity penalty\n",
        "        category_penalty = diversity_penalty if category in selected_categories else 0\n",
        "        brand_penalty = diversity_penalty * 0.5 if brand in selected_brands else 0\n",
        "\n",
        "        final_score = adjusted_scores[idx] * (1 - category_penalty - brand_penalty)\n",
        "\n",
        "        # Add if score is still competitive\n",
        "        if not selected or final_score >= adjusted_scores[selected[0][0]] * 0.7:\n",
        "            selected.append((idx, final_score))\n",
        "            selected_categories.add(category)\n",
        "            selected_brands.add(brand)\n",
        "\n",
        "    # Build results\n",
        "    results = []\n",
        "    for rank, (idx, final_score) in enumerate(selected, 1):\n",
        "        product_row = products_df.iloc[idx]\n",
        "\n",
        "        # Calculate component scores for display\n",
        "        specificity = calculate_specificity_score(product_row)\n",
        "        precision = calculate_match_precision(product_row, query_skin_types)\n",
        "\n",
        "        results.append({\n",
        "            'rank': rank,\n",
        "            'name': product_row['name'],\n",
        "            'brand': product_row['brand'],\n",
        "            'category': product_row['Label'],\n",
        "            'price': product_row['price'],\n",
        "            'rating': product_row['rank'],\n",
        "            'base_score': base_scores[idx],\n",
        "            'adjusted_score': adjusted_scores[idx],\n",
        "            'specificity': specificity,\n",
        "            'precision': precision,\n",
        "            'skin_types': ', '.join([\n",
        "                st for st in ['Dry', 'Oily', 'Combination', 'Normal', 'Sensitive']\n",
        "                if product_row[st] == 1\n",
        "            ])\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def display_results_with_details(results, query):\n",
        "    \"\"\"Display recommendations with scoring breakdown.\"\"\"\n",
        "    print(f\" QUERY: '{query}'\")\n",
        "    print(f\" TOP {len(results)} RECOMMENDATIONS (Specificity-Aware):\\n\")\n",
        "\n",
        "    for r in results:\n",
        "        print(f\"#{r['rank']}. {r['name']}\")\n",
        "        print(f\"    Brand:         {r['brand']}\")\n",
        "        print(f\"    Category:      {r['category']}\")\n",
        "        print(f\"    Price:         ${r['price']:.2f}\")\n",
        "        print(f\"    Rating:        {r['rating']:.1f}/5.0\")\n",
        "        print(f\"    For:           {r['skin_types']}\")\n",
        "        print(f\"    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n",
        "        print(f\"    Base Score:    {r['base_score']:.1%} (model prediction)\")\n",
        "        print(f\"    Specificity:   {r['specificity']:.1%} (how targeted)\")\n",
        "        print(f\"    Precision:     {r['precision']:.1%} (query match)\")\n",
        "        print(f\"    Final Score:   {r['adjusted_score']:.1%} \")\n",
        "        print()\n",
        "\n",
        "\n",
        "# TESTING THE FIX\n",
        "def test_improved_system():\n",
        "    \"\"\"\n",
        "    Test the improved ranking system with various queries.\n",
        "    \"\"\"\n",
        "    print(\" TESTING IMPROVED RANKING SYSTEM\")\n",
        "\n",
        "    test_queries = [\n",
        "        \"dry sensitive skin with redness\",\n",
        "        \"oily acne prone skin\",\n",
        "        \"combination skin occasional breakouts\",\n",
        "        \"mature skin with wrinkles\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\nComparing OLD vs NEW rankings:\\n\")\n",
        "\n",
        "    for query in test_queries:\n",
        "        print(f\"\\n{'─'*80}\")\n",
        "        print(f\"Query: '{query}'\")\n",
        "        print(f\"{'─'*80}\")\n",
        "\n",
        "        # Get old results (just base scores)\n",
        "        adjusted_scores, base_scores, query_skin_types = get_reranked_scores(\n",
        "            query, model, sbert_model, products_df,\n",
        "            product_embeddings, price_rank_features, device,\n",
        "            specificity_weight=0.0, precision_weight=0.0  # No adjustment\n",
        "        )\n",
        "        old_top5 = base_scores.argsort()[-5:][::-1]\n",
        "\n",
        "        # Get new results (with specificity/precision)\n",
        "        new_results = recommend_top_k_improved(\n",
        "            query, model, sbert_model, products_df,\n",
        "            product_embeddings, price_rank_features, device,\n",
        "            k=5, specificity_weight=0.3, precision_weight=0.2\n",
        "        )\n",
        "\n",
        "        print(\"\\nOLD (Generic products dominate):\")\n",
        "        for i, idx in enumerate(old_top5, 1):\n",
        "            row = products_df.iloc[idx]\n",
        "            skin_count = sum([row[st] for st in ['Dry', 'Oily', 'Combination', 'Normal', 'Sensitive']])\n",
        "            print(f\"  {i}. {row['name'][:45]} ({skin_count} skin types)\")\n",
        "\n",
        "        print(\"\\nNEW (Specific products prioritized):\")\n",
        "        for r in new_results:\n",
        "            skin_count = r['skin_types'].count(',') + 1\n",
        "            print(f\"  {r['rank']}. {r['name'][:45]} ({skin_count} skin types, {r['specificity']:.0%} specific)\")\n",
        "\n",
        "        print()"
      ],
      "metadata": {
        "id": "sq2U3IkQ48yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TESTING (cell1 and cell2)"
      ],
      "metadata": {
        "id": "GwrxkOZTVdfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Test the improved system\n",
        "#test_improved_system()"
      ],
      "metadata": {
        "id": "mc-wjSxB5BSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Try one specific query with details\n",
        "results = recommend_top_k_improved(\n",
        "    \"oily acne prone skin\",\n",
        "    model, sbert_model, products_df,\n",
        "    product_embeddings, price_rank_features, device,\n",
        "    k=5,\n",
        "    specificity_weight=0.3,\n",
        "    precision_weight=0.2\n",
        ")\n",
        "\n",
        "#display_results_with_details(results, \"oily acne prone skin\")"
      ],
      "metadata": {
        "id": "yY46KbnA5DCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPROVING TOP K PRODUCTS WITH FILTER"
      ],
      "metadata": {
        "id": "olmrMUzeVkHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick fix: Filter out products with no skin type data\n",
        "def recommend_top_k_improved_filtered(query, model, sbert_model, products_df,\n",
        "                                     product_embeddings, price_rank_features, device,\n",
        "                                     k=5, specificity_weight=0.3, precision_weight=0.2,\n",
        "                                     diversity_penalty=0.15):\n",
        "    \"\"\"\n",
        "    Improved recommendation that filters out products with no skin type data.\n",
        "    \"\"\"\n",
        "    # Get base results\n",
        "    adjusted_scores, base_scores, query_skin_types = get_reranked_scores(\n",
        "        query, model, sbert_model, products_df,\n",
        "        product_embeddings, price_rank_features, device,\n",
        "        specificity_weight, precision_weight\n",
        "    )\n",
        "\n",
        "    # Filter: only keep products with at least one skin type\n",
        "    valid_products = []\n",
        "    for i in range(len(products_df)):\n",
        "        skin_type_count = sum([\n",
        "            products_df.iloc[i][st] for st in ['Dry', 'Oily', 'Combination', 'Normal', 'Sensitive']\n",
        "        ])\n",
        "        if skin_type_count > 0:  # Has at least one skin type\n",
        "            valid_products.append(i)\n",
        "\n",
        "    # Get scores only for valid products\n",
        "    valid_scores = adjusted_scores[valid_products]\n",
        "\n",
        "    # Get top candidates from valid products\n",
        "    num_candidates = min(k * 3, len(valid_products))\n",
        "    top_candidate_indices = valid_scores.argsort()[-num_candidates:][::-1]\n",
        "    top_candidates_idx = [valid_products[i] for i in top_candidate_indices]\n",
        "\n",
        "    # Select diverse set\n",
        "    selected = []\n",
        "    selected_categories = set()\n",
        "    selected_brands = set()\n",
        "\n",
        "    for idx in top_candidates_idx:\n",
        "        if len(selected) >= k:\n",
        "            break\n",
        "\n",
        "        category = products_df.iloc[idx]['Label']\n",
        "        brand = products_df.iloc[idx]['brand']\n",
        "\n",
        "        category_penalty = diversity_penalty if category in selected_categories else 0\n",
        "        brand_penalty = diversity_penalty * 0.5 if brand in selected_brands else 0\n",
        "\n",
        "        final_score = adjusted_scores[idx] * (1 - category_penalty - brand_penalty)\n",
        "\n",
        "        if not selected or final_score >= adjusted_scores[selected[0][0]] * 0.7:\n",
        "            selected.append((idx, final_score))\n",
        "            selected_categories.add(category)\n",
        "            selected_brands.add(brand)\n",
        "\n",
        "    # Build results\n",
        "    results = []\n",
        "    for rank, (idx, final_score) in enumerate(selected, 1):\n",
        "        product_row = products_df.iloc[idx]\n",
        "        specificity = calculate_specificity_score(product_row)\n",
        "        precision = calculate_match_precision(product_row, query_skin_types)\n",
        "\n",
        "        results.append({\n",
        "            'rank': rank,\n",
        "            'name': product_row['name'],\n",
        "            'brand': product_row['brand'],\n",
        "            'category': product_row['Label'],\n",
        "            'price': product_row['price'],\n",
        "            'rating': product_row['rank'],\n",
        "            'base_score': base_scores[idx],\n",
        "            'adjusted_score': adjusted_scores[idx],\n",
        "            'specificity': specificity,\n",
        "            'precision': precision,\n",
        "            'skin_types': ', '.join([\n",
        "                st for st in ['Dry', 'Oily', 'Combination', 'Normal', 'Sensitive']\n",
        "                if product_row[st] == 1\n",
        "            ])\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "#Test it\n",
        "#print(\"Testing with skin type filter:\\n\")\n",
        "#results = recommend_top_k_improved_filtered(\n",
        "    #\"oily acne prone skin\",\n",
        "    #model, sbert_model, products_df,\n",
        "    #product_embeddings, price_rank_features, device,\n",
        "    #k=5\n",
        "#)\n",
        "#display_results_with_details(results, \"oily acne prone skin\")\n"
      ],
      "metadata": {
        "id": "jpS92fbK5gQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPROVED RECOMMEND ROUTINE WITH ADJUSTED SCORES"
      ],
      "metadata": {
        "id": "KeY7Qvm2NzCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_routine_improved(query):\n",
        "    \"\"\"\n",
        "    Build a routine using the improved specificity-aware ranking.\n",
        "    \"\"\"\n",
        "    adjusted_scores, base_scores, query_skin_types = get_reranked_scores(\n",
        "        query, model, sbert_model, products_df,\n",
        "        product_embeddings, price_rank_features, device,\n",
        "        specificity_weight=0.3, precision_weight=0.2\n",
        "    )\n",
        "\n",
        "    routine_categories = [\n",
        "        'Cleanser',\n",
        "        'Treatment',\n",
        "        'Eye cream',\n",
        "        'Moisturizer',\n",
        "        'Sun protect',\n",
        "        'Face Mask'\n",
        "    ]\n",
        "\n",
        "    routine = {}\n",
        "\n",
        "    for category in routine_categories:\n",
        "        # Filter by category AND skin type data\n",
        "        category_mask = products_df['Label'] == category\n",
        "\n",
        "        # Only include products with skin type data\n",
        "        valid_products = []\n",
        "        for idx in products_df[category_mask].index:\n",
        "            skin_type_count = sum([\n",
        "                products_df.iloc[idx][st] for st in ['Dry', 'Oily', 'Combination', 'Normal', 'Sensitive']\n",
        "            ])\n",
        "            if skin_type_count > 0:\n",
        "                valid_products.append(idx)\n",
        "\n",
        "        if len(valid_products) == 0:\n",
        "            continue\n",
        "\n",
        "        # Get ADJUSTED scores\n",
        "        category_scores = adjusted_scores[valid_products]\n",
        "\n",
        "        # Get best product\n",
        "        best_local_idx = category_scores.argmax()\n",
        "        best_global_idx = valid_products[best_local_idx]\n",
        "\n",
        "        product_row = products_df.iloc[best_global_idx]\n",
        "\n",
        "        routine[category] = {\n",
        "            'name': product_row['name'],\n",
        "            'brand': product_row['brand'],\n",
        "            'price': product_row['price'],\n",
        "            'rating': product_row['rank'],\n",
        "            'compatibility_score': adjusted_scores[best_global_idx],\n",
        "            'specificity': calculate_specificity_score(product_row),\n",
        "            'skin_types': ', '.join([\n",
        "                st for st in ['Dry', 'Oily', 'Combination', 'Normal', 'Sensitive']\n",
        "                if product_row[st] == 1\n",
        "            ])\n",
        "        }\n",
        "\n",
        "    return routine"
      ],
      "metadata": {
        "id": "pksWAq4b6m7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PRODUCTION-READY INTERACTIVE DEMO WITH IMPROVED RANKING\n",
        "\n",
        "def interactive_session_improved():\n",
        "    \"\"\"\n",
        "    Interactive demo with the new specificity-aware ranking.\n",
        "    \"\"\"\n",
        "    print(\" IMPROVED INTERACTIVE MODE\")\n",
        "    print(\"\\nYou can now test the improved recommendation system!\")\n",
        "    print(\"Commands:\")\n",
        "    print(\"  - Type a skincare concern (e.g., 'dry skin with acne')\")\n",
        "    print(\"  - Type 'routine' before your query for a full routine\")\n",
        "    print(\"  - Type 'quit' to exit\")\n",
        "    print(\"\\n NEW: Now recommends specific products tailored to your skin!\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\" Enter query (or 'quit'): \").strip()\n",
        "\n",
        "        if user_input.lower() == 'quit':\n",
        "            print(\"\\n Thanks for using the improved demo!\")\n",
        "            break\n",
        "\n",
        "        if not user_input:\n",
        "            continue\n",
        "\n",
        "        # Check if user wants routine\n",
        "        if user_input.lower().startswith('routine'):\n",
        "            query = user_input[7:].strip()\n",
        "            if not query:\n",
        "                query = input(\"   Enter your skin concerns: \").strip()\n",
        "\n",
        "            routine = recommend_routine_improved(query)\n",
        "            display_routine(routine, query)\n",
        "        else:\n",
        "            query = user_input\n",
        "\n",
        "            # New improved function\n",
        "            results = recommend_top_k_improved_filtered(\n",
        "                query, model, sbert_model, products_df,\n",
        "                product_embeddings, price_rank_features, device,\n",
        "                k=5,\n",
        "                specificity_weight=0.3,  # Penalize generic products\n",
        "                precision_weight=0.2     # Reward precise matches\n",
        "            )\n",
        "\n",
        "            display_results_with_details(results, query)\n",
        "\n",
        "        print()\n",
        "\n",
        "# Start the improved demo\n",
        "print(\" READY TO TEST!\")\n",
        "print(\"\\nYour improved recommendation system is ready.\")\n",
        "print(\"Run: interactive_session_improved()\")\n",
        "print(\"\\nOr test specific queries:\")\n",
        "print(\"  - 'dry sensitive skin'\")\n",
        "print(\"  - 'oily acne prone'\")\n",
        "print(\"  - 'mature skin wrinkles'\")\n",
        "print(\"  - 'combination skin breakouts'\")"
      ],
      "metadata": {
        "id": "2MuXiEJhUB6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interactive_session_improved()"
      ],
      "metadata": {
        "id": "A5npXsOyShig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Enhancement Statistics Calculator\n",
        "Run this after your improved interactive demo to generate statistics for your report\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# METRIC 1: Average Specificity Score\n",
        "\n",
        "def get_top5_old(query):\n",
        "    \"\"\"Get top 5 using OLD method (no penalties).\"\"\"\n",
        "    query_emb = sbert_model.encode([query], normalize_embeddings=True)[0]\n",
        "\n",
        "    batch_features = []\n",
        "    for i in range(len(products_df)):\n",
        "        product_emb = product_embeddings[i]\n",
        "        numerical = price_rank_features[i]\n",
        "        features = np.concatenate([query_emb, product_emb, numerical])\n",
        "        batch_features.append(features)\n",
        "\n",
        "    batch_tensor = torch.FloatTensor(np.array(batch_features)).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        scores = model(batch_tensor).cpu().numpy().flatten()\n",
        "\n",
        "    top_5_idx = scores.argsort()[-5:][::-1]\n",
        "    return top_5_idx\n",
        "\n",
        "\n",
        "def get_top5_new(query):\n",
        "    \"\"\"Get top 5 using NEW method (with penalties).\"\"\"\n",
        "    results = recommend_top_k_improved_filtered(\n",
        "        query, model, sbert_model, products_df,\n",
        "        product_embeddings, price_rank_features, device,\n",
        "        k=5, specificity_weight=0.3, precision_weight=0.2\n",
        "    )\n",
        "\n",
        "    # Get indices\n",
        "    top_5_idx = []\n",
        "    for r in results:\n",
        "        idx = products_df[products_df['name'] == r['name']].index[0]\n",
        "        top_5_idx.append(idx)\n",
        "\n",
        "    return top_5_idx\n",
        "\n",
        "\n",
        "def calculate_metrics_for_query(query, method='old'):\n",
        "    \"\"\"Calculate all metrics for a single query.\"\"\"\n",
        "    if method == 'old':\n",
        "        top_5_idx = get_top5_old(query)\n",
        "    else:\n",
        "        top_5_idx = get_top5_new(query)\n",
        "\n",
        "    # Metric 1: Average Specificity\n",
        "    specificities = []\n",
        "    for idx in top_5_idx:\n",
        "        product = products_df.iloc[idx]\n",
        "        spec = calculate_specificity_score(product)\n",
        "        specificities.append(spec)\n",
        "    avg_specificity = np.mean(specificities)\n",
        "\n",
        "    # Metric 2: Generic Product Count (5 skin types)\n",
        "    generic_count = 0\n",
        "    for idx in top_5_idx:\n",
        "        skin_count = sum([\n",
        "            products_df.iloc[idx][st]\n",
        "            for st in ['Dry', 'Oily', 'Combination', 'Normal', 'Sensitive']\n",
        "        ])\n",
        "        if skin_count == 5:\n",
        "            generic_count += 1\n",
        "\n",
        "    # Metric 3: Category Diversity\n",
        "    categories = [products_df.iloc[idx]['Label'] for idx in top_5_idx]\n",
        "    unique_categories = len(set(categories))\n",
        "\n",
        "    # Metric 4: Brand Diversity\n",
        "    brands = [products_df.iloc[idx]['brand'] for idx in top_5_idx]\n",
        "    unique_brands = len(set(brands))\n",
        "\n",
        "    return {\n",
        "        'avg_specificity': avg_specificity,\n",
        "        'generic_count': generic_count,\n",
        "        'category_diversity': unique_categories,\n",
        "        'brand_diversity': unique_brands,\n",
        "        'top_5_indices': top_5_idx\n",
        "    }\n",
        "\n",
        "\n",
        "# RUN EVALUATION ON TEST QUERIES\n",
        "\n",
        "print(\"ENHANCEMENT EVALUATION STATISTICS\")\n",
        "\n",
        "test_queries = [\n",
        "    \"dry sensitive skin\",\n",
        "    \"oily acne prone\",\n",
        "    \"combination skin breakouts\",\n",
        "    \"mature skin wrinkles\",\n",
        "    \"sensitive skin redness\",\n",
        "    \"oily skin large pores\",\n",
        "    \"dry skin fine lines\",\n",
        "    \"normal skin hydration\"\n",
        "]\n",
        "\n",
        "results_data = []\n",
        "\n",
        "print(\"\\nEvaluating queries...\\n\")\n",
        "\n",
        "for query in test_queries:\n",
        "    old_metrics = calculate_metrics_for_query(query, 'old')\n",
        "    new_metrics = calculate_metrics_for_query(query, 'new')\n",
        "\n",
        "    results_data.append({\n",
        "        'query': query,\n",
        "        'old_specificity': old_metrics['avg_specificity'],\n",
        "        'new_specificity': new_metrics['avg_specificity'],\n",
        "        'old_generic_count': old_metrics['generic_count'],\n",
        "        'new_generic_count': new_metrics['generic_count'],\n",
        "        'old_category_div': old_metrics['category_diversity'],\n",
        "        'new_category_div': new_metrics['category_diversity'],\n",
        "        'old_brand_div': old_metrics['brand_diversity'],\n",
        "        'new_brand_div': new_metrics['brand_diversity']\n",
        "    })\n",
        "\n",
        "# Create DataFrame\n",
        "results_df = pd.DataFrame(results_data)\n",
        "\n",
        "# SUMMARY STATISTICS\n",
        "print(\"SUMMARY STATISTICS\")\n",
        "\n",
        "print(\"\\n1. SPECIFICITY SCORE (0-1, higher = more targeted)\")\n",
        "print(\"-\" * 60)\n",
        "old_spec_mean = results_df['old_specificity'].mean()\n",
        "new_spec_mean = results_df['new_specificity'].mean()\n",
        "spec_improvement = (new_spec_mean - old_spec_mean) / old_spec_mean * 100\n",
        "\n",
        "print(f\"Before Enhancement: {old_spec_mean:.3f}\")\n",
        "print(f\"After Enhancement:  {new_spec_mean:.3f}\")\n",
        "print(f\"Improvement:        +{spec_improvement:.1f}%\")\n",
        "\n",
        "print(\"\\n2. GENERIC PRODUCTS IN TOP 5 (lower = better)\")\n",
        "print(\"-\" * 60)\n",
        "old_generic_mean = results_df['old_generic_count'].mean()\n",
        "new_generic_mean = results_df['new_generic_count'].mean()\n",
        "generic_reduction = (old_generic_mean - new_generic_mean) / old_generic_mean * 100\n",
        "\n",
        "print(f\"Before Enhancement: {old_generic_mean:.2f} / 5\")\n",
        "print(f\"After Enhancement:  {new_generic_mean:.2f} / 5\")\n",
        "print(f\"Reduction:          -{generic_reduction:.1f}%\")\n",
        "\n",
        "print(\"\\n3. CATEGORY DIVERSITY (out of 5 products)\")\n",
        "print(\"-\" * 60)\n",
        "old_cat_mean = results_df['old_category_div'].mean()\n",
        "new_cat_mean = results_df['new_category_div'].mean()\n",
        "cat_improvement = (new_cat_mean - old_cat_mean) / old_cat_mean * 100\n",
        "\n",
        "print(f\"Before Enhancement: {old_cat_mean:.2f} unique categories\")\n",
        "print(f\"After Enhancement:  {new_cat_mean:.2f} unique categories\")\n",
        "print(f\"Improvement:        +{cat_improvement:.1f}%\")\n",
        "\n",
        "print(\"\\n4. BRAND DIVERSITY (out of 5 products)\")\n",
        "print(\"-\" * 60)\n",
        "old_brand_mean = results_df['old_brand_div'].mean()\n",
        "new_brand_mean = results_df['new_brand_div'].mean()\n",
        "brand_improvement = (new_brand_mean - old_brand_mean) / old_brand_mean * 100\n",
        "\n",
        "print(f\"Before Enhancement: {old_brand_mean:.2f} unique brands\")\n",
        "print(f\"After Enhancement:  {new_brand_mean:.2f} unique brands\")\n",
        "print(f\"Improvement:        +{brand_improvement:.1f}%\")\n",
        "\n",
        "# DETAILED QUERY-BY-QUERY RESULTS\n",
        "print(\"DETAILED RESULTS BY QUERY\")\n",
        "\n",
        "for _, row in results_df.iterrows():\n",
        "    print(f\"\\nQuery: '{row['query']}'\")\n",
        "    print(f\"  Specificity:  {row['old_specificity']:.2f} → {row['new_specificity']:.2f}\")\n",
        "    print(f\"  Generic (5ST): {row['old_generic_count']}/5 → {row['new_generic_count']}/5\")\n",
        "    print(f\"  Categories:   {row['old_category_div']}/5 → {row['new_category_div']}/5\")\n",
        "    print(f\"  Brands:       {row['old_brand_div']}/5 → {row['new_brand_div']}/5\")\n",
        "\n",
        "# VISUALIZATIONS\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"GENERATING VISUALIZATIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "fig.suptitle('Enhancement Impact Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Plot 1: Specificity Comparison\n",
        "ax1 = axes[0, 0]\n",
        "x = np.arange(len(results_df))\n",
        "width = 0.35\n",
        "ax1.bar(x - width/2, results_df['old_specificity'], width, label='Before', alpha=0.7, color='#e74c3c')\n",
        "ax1.bar(x + width/2, results_df['new_specificity'], width, label='After', alpha=0.7, color='#2ecc71')\n",
        "ax1.set_xlabel('Query')\n",
        "ax1.set_ylabel('Specificity Score')\n",
        "ax1.set_title('Average Specificity of Top 5 Products')\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(range(1, len(results_df)+1))\n",
        "ax1.legend()\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Plot 2: Generic Product Count\n",
        "ax2 = axes[0, 1]\n",
        "ax2.bar(x - width/2, results_df['old_generic_count'], width, label='Before', alpha=0.7, color='#e74c3c')\n",
        "ax2.bar(x + width/2, results_df['new_generic_count'], width, label='After', alpha=0.7, color='#2ecc71')\n",
        "ax2.set_xlabel('Query')\n",
        "ax2.set_ylabel('Generic Products (5 Skin Types)')\n",
        "ax2.set_title('Generic Products in Top 5')\n",
        "ax2.set_xticks(x)\n",
        "ax2.set_xticklabels(range(1, len(results_df)+1))\n",
        "ax2.set_ylim(0, 5)\n",
        "ax2.legend()\n",
        "ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Plot 3: Summary Metrics\n",
        "ax3 = axes[1, 0]\n",
        "metrics = ['Specificity\\n(0-1)', 'Generic Count\\n(inverted)', 'Category\\nDiversity', 'Brand\\nDiversity']\n",
        "old_vals = [\n",
        "    old_spec_mean,\n",
        "    1 - old_generic_mean/5,  # Invert so higher is better\n",
        "    old_cat_mean/5,\n",
        "    old_brand_mean/5\n",
        "]\n",
        "new_vals = [\n",
        "    new_spec_mean,\n",
        "    1 - new_generic_mean/5,\n",
        "    new_cat_mean/5,\n",
        "    new_brand_mean/5\n",
        "]\n",
        "x_pos = np.arange(len(metrics))\n",
        "ax3.bar(x_pos - width/2, old_vals, width, label='Before', alpha=0.7, color='#e74c3c')\n",
        "ax3.bar(x_pos + width/2, new_vals, width, label='After', alpha=0.7, color='#2ecc71')\n",
        "ax3.set_ylabel('Normalized Score')\n",
        "ax3.set_title('Overall Improvement Summary')\n",
        "ax3.set_xticks(x_pos)\n",
        "ax3.set_xticklabels(metrics, fontsize=9)\n",
        "ax3.set_ylim(0, 1)\n",
        "ax3.legend()\n",
        "ax3.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Plot 4: Improvement Percentages\n",
        "ax4 = axes[1, 1]\n",
        "improvements = [\n",
        "    spec_improvement,\n",
        "    -generic_reduction,  # Negative because reduction is good\n",
        "    cat_improvement,\n",
        "    brand_improvement\n",
        "]\n",
        "improvement_labels = ['Specificity', 'Generic\\nReduction', 'Category\\nDiversity', 'Brand\\nDiversity']\n",
        "colors = ['#2ecc71' if x > 0 else '#e74c3c' for x in improvements]\n",
        "bars = ax4.barh(improvement_labels, improvements, color=colors, alpha=0.7)\n",
        "ax4.set_xlabel('Improvement (%)')\n",
        "ax4.set_title('Percentage Improvements')\n",
        "ax4.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
        "ax4.grid(axis='x', alpha=0.3)\n",
        "for i, (bar, val) in enumerate(zip(bars, improvements)):\n",
        "    ax4.text(val + (2 if val > 0 else -2), i, f'{val:.1f}%',\n",
        "             va='center', ha='left' if val > 0 else 'right', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('enhancement_statistics.png', dpi=300, bbox_inches='tight')\n",
        "print(\"\\n Saved: enhancement_statistics.png\")\n",
        "\n",
        "# EXPORT RESULTS TABLE\n",
        "# Create formatted table for report\n",
        "export_df = results_df.copy()\n",
        "export_df['spec_change'] = ((export_df['new_specificity'] - export_df['old_specificity'])\n",
        "                             / export_df['old_specificity'] * 100)\n",
        "export_df['generic_change'] = ((export_df['old_generic_count'] - export_df['new_generic_count'])\n",
        "                                / export_df['old_generic_count'].replace(0, 1) * 100)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXPORTABLE TABLE FOR REPORT\")\n",
        "print(\"=\"*80)\n",
        "print(export_df[['query', 'old_specificity', 'new_specificity', 'spec_change',\n",
        "                 'old_generic_count', 'new_generic_count']].to_string(index=False))\n",
        "\n",
        "# Save to CSV\n",
        "export_df.to_csv('enhancement_results.csv', index=False)\n",
        "print(\"\\nSaved: enhancement_results.csv\")"
      ],
      "metadata": {
        "id": "MOlzPCi-abPY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}